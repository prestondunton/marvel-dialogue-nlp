{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marvel Dialogue Classification\n",
    "#### CS 345 Final Project\n",
    "By: Preston Dunton  \n",
    "December 8, 2020\n",
    "\n",
    "<img src=\"https://blog.umhb.edu/wp-content/uploads/2019/06/mcu-1920x1080.jpg\" alt=\"MCU Banner\" width=\"60%\" height=\"60%\" align=\"center\">\n",
    "\n",
    "## Table of Contents\n",
    "- [**Introduction**](#introduction)\n",
    "    - [The Problem](#the-problem)\n",
    "    - [About the Dataset](#about-the-dataset)\n",
    "- [**Methods**](#methods)\n",
    "    - [Grid Searching](#grid-searching)\n",
    "    - [Stop Words](#stop-words)\n",
    "    - [Stemming](#stemming)\n",
    "    - [TF / IDF Transformations](#tfidf)\n",
    "    - [Imports, Constants, and Classes](#imports-constants-classes)\n",
    "    - [Preliminary Data Analysis](#data-analysis)\n",
    "        - [Line Count Distributions](#line-count-distributions)\n",
    "        - [Words Per Line Distributions](#words-per-line-distributions)\n",
    "    - [Dataset Preprocessing](#preprocessing)\n",
    "    - [Models](#models)\n",
    "        - [Model 1](#model1)\n",
    "        - [Model 2](#model2)\n",
    "        - [Model 3](#model3)\n",
    "        - [Model 4](#model4)\n",
    "        - [Model 5](#model5)\n",
    "        - [Model 6](#model6)\n",
    "        - [Model 7](#model7)\n",
    "        - [Model 8](#model8)\n",
    "        - [Model 9](#model9)\n",
    "        - [Model 10](#model10)\n",
    "        - [Model 11](#model11)\n",
    "        - [Model 12](#model12)\n",
    "- [**Results**](#results)\n",
    "    - [Cross Validation Scores (Balanced Accuracy)](#cvscores)\n",
    "    - [Best Model](#best-model)\n",
    "    - [Baseline Comparisons](#baselines)\n",
    "        - [Majority Classifier](#majority-classifier)\n",
    "        - [Random Classifier](#random-classifier)\n",
    "        - [Comparison with Model 4](#comparison-model-4)\n",
    "    - [Confusion Matrix](#confusion-matrix)\n",
    "    - [Learning Curves](#learning-curves)\n",
    "- [**Conclusions**](#conclusions)\n",
    "    - [Project Improvements](#project-improvements)\n",
    "    - [Takeaways](#takeaways)\n",
    "    - [Moving Forward](#moving-forward)\n",
    "- [**Sources**](#sources)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  <a name=\"introduction\"></a>\n",
    "This notebook summarizes the project that can be found in [this repository](https://github.com/prestondunton/marvel-dialogue-nlp). This project is my final project for CS 345, Machine Learning Foundations and Practice, at Colorado State University (Fall 2020).  The goals of this project were for me to apply what I've learned this semester, as well as introduce me into NLP problems and methods.\n",
    "\n",
    "\n",
    "## The Problem <a name=\"the-problem\"></a>\n",
    "The problem whished to be accomplished in this project is an NLP classification problem.  The goal was to create a model that can predict a character's name given a line of their dialogue from a Marvel Cinematic Universe (MCU) movie.  Data was taken from Marvel released scripts and transformed into labels of names and feature documents of their dialogue.\n",
    "\n",
    "\n",
    "## About the Dataset <a name=\"about-the-dataset\"></a>\n",
    "This repository contains a newly created dataset to train and test models on, as well as several Jupyter Notebooks that describe the process used to create each `.csv`.  These Jupyter notebooks explain the process of parsing the `.pdf`s with the `pandas` library.  The end file, [mcu.csv](https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/data/mcu.csv), contains columns `character` and `line` that hold the dialogue for several movies from the MCU. There are more columns that provide additional features for context, but were not used in this project.  See [/data/MCU.ipynb](https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/data/MCU.ipynb) for more details on those features. For individual movies, the corresponding `.csv` can be found in [/data/cleaned/](https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/data/cleaned) and contain columns `character` and `line`.  Each movie file was created using the same partially automated process, though improvements were found as more movies were processed.\n",
    "\n",
    "The movie script `.pdf`s were obtained from [Script Slug](https://www.scriptslug.com/scripts/category/marvel), though other copies of the Marvel released scripts can be found online elsewhere.  Only a few of the MCU movie scripts were released, so this dataset only contains a subset of the movies in the MCU (listed below).  Transcripts exist for all 21 movies, though these transcripts can contain many errors, so they were not used.  Additionally, creating each `.csv` took quite a bit of time (approximately 12 hours per movie), so currently, this dataset only contains 5 movies (listed below).\n",
    "\n",
    "\n",
    "| MCU Movies on Script Slug             | Included in Project |\n",
    "| ------------------------------------- | ------------------- |\n",
    "| Iron Man (2008)                       | ✔️                 | \n",
    "| The Avengers (2012)                   | ✔️                 |\n",
    "| Thor: Ragnorak (2017)                 | ✔️                 |\n",
    "| Guardians of the Galaxy Vol. 2 (2017) | ✔️                 |\n",
    "| Avengers Endgame (2019)               | ✔️                 |\n",
    "| Thor (2011)                           | ❌                  |\n",
    "| Captain America (2011)                | ❌                  |\n",
    "| Black Panther (2018)                  | ❌                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods  <a name=\"methods\"></a>\n",
    "\n",
    "In order to accomplish the task described above, 12 models were created.  These models employ different combinations of NLP techniques and different ML classifiers.  A summary of the architecture of the 12 models, as well as an explaination of this project's use of each NLP technique, is below.\n",
    "\n",
    "| Model # | Classifier    | Uses Stemming | Uses TF / IDF Transformation |\n",
    "| ------- | ------------- | -------- | ---------------------------- |\n",
    "| 1       | Naive Bayes   | ❌      | ❌                           |\n",
    "| 2       | Naive Bayes   | ❌      | ✔️                           |\n",
    "| 3       | Naive Bayes   | ✔️      | ❌                           |\n",
    "| 4       | Naive Bayes   | ✔️      | ✔️                           |\n",
    "| 5       | Random Forest | ❌      | ❌                           |\n",
    "| 6       | Random Forest | ❌      | ✔️                           |\n",
    "| 7       | Random Forest | ✔️      | ❌                           |\n",
    "| 8       | Random Forest | ✔️      | ✔️                           |\n",
    "| 9       | SVM           | ❌      | ❌                           |\n",
    "| 10      | SVM           | ❌      | ✔️                           |\n",
    "| 11      | SVM           | ✔️      | ❌                           |\n",
    "| 12      | SVM           | ✔️      | ✔️                           |\n",
    "\n",
    "\n",
    "## Grid Searching <a name=\"grid-searching\"></a>\n",
    "\n",
    "Scikit-learn provides an interface for model selection called `GridSearchCV` which uses cross validation to select the best combination of hyperparameters for a given model.  10 of the models (1,2,3,4,5,6,7,9,10,11) use `GridSearchCV` to select the best performing parameters for the `CountVectorizer` (or the custom `StemCountVectorizer` if the model uses stemming).  Models 8 and 12 do not use GridSearchCV, because the estimated compute time for searching every combination of defined parameters was too large (19 and 90 hours respectively). Instead, model 8 uses parameters from model 6, and model 12 uses parameters from model 10, which both the same architecture as the first except for the use of stemming.  It should also be noted that the other 10 models were trained from the same options of parameters, so that they could be compared with each other.\n",
    "\n",
    "## Stop Words <a name=\"stop-words\"></a>\n",
    "\n",
    "The removal of non-important words from the feature documents, called \"stop words,\" is often an important step in NLP problems.  Stop words like `[\"the\",\"I\", \"we\", \"she\" ...]` often don't provide any value to a model. Three options were provided to `GridSearchCV` for removing stop words.  The first is `None`, which means don't remove stop words.  The other two options are two different sets of stop words, the `english` set provided by Scikit-learn, and the `english` set provided by NLTK, which was included because the documentation for Scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) recommends a different set of stop words.\n",
    "\n",
    "\n",
    "## Stemming <a name=\"stemming\"></a>\n",
    "\n",
    "Stemming is the process of taking derrived words, such as verb conjugations and plurals, and transforming them back into their base versions.  For example, \"fishing,\" \"fished,\" and \"fishes\" might all be stemmed into \"fish.\"  Stemming is useful in NLP because it allows the word count features to group derrived words by their base words.  In this project, NLTK's Snowball Stemmer is used in a custom class that extends Scikit-learn's `CountVectorizer`.  See Javed Shaikh's article in the Sources section for the inspiration for this approach.\n",
    "\n",
    "\n",
    "## TF / IDF Transformations <a name=\"tfidf\"></a>\n",
    "\n",
    "The Term Frequency and Inverse Document Frequency transformations in this project are done by Scikit-learn's `TfidfTransformer`.  The parameter `use_idf` is an option for `GridSearchCV` to use when tuning hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Constants, and Classes <a name=\"imports-constants-classes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "DESCRIBE_PERCENTILES = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "\n",
    "class StemCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemCountVectorizer, self).build_analyzer()\n",
    "        \n",
    "        return lambda document: ([SnowballStemmer('english', ignore_stopwords=True).stem(word) for word in analyzer(document)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcu = pd.read_csv(\"./data/mcu.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis <a name=\"data-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Count Distributions <a name=\"line-count-distributions\"></a>\n",
    "\n",
    "This cell explores the distribution of how many lines each character has in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.758065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>71.731787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>75.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>140.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>289.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>643.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total\n",
       "count  186.000000\n",
       "mean    26.758065\n",
       "std     71.731787\n",
       "min      1.000000\n",
       "25%      1.000000\n",
       "50%      4.000000\n",
       "75%     15.750000\n",
       "90%     75.500000\n",
       "95%    140.500000\n",
       "99%    289.200000\n",
       "max    643.000000"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_count = pd.DataFrame(mcu.groupby([\"movie\",\"character\"]).line.nunique())\n",
    "line_count.reset_index(inplace=True)\n",
    "line_count = line_count.pivot(index=\"character\", columns=\"movie\", values=\"line\")\n",
    "line_count.fillna(0, inplace=True)\n",
    "line_count[\"total\"] = line_count.sum(axis=1)\n",
    "line_count = line_count.astype(\"int64\")\n",
    "line_count.sort_values(by=\"total\", ascending=False)\n",
    "\n",
    "line_count['total'].hist(bins=60)\n",
    "pd.DataFrame(line_count['total']).describe(percentiles = DESCRIBE_PERCENTILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words Per Line Distribution <a name=\"words-per-line-distributions\"></a>\n",
    "\n",
    "This cell explores the distribution of the number of words per line of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5044.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.236915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.598077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words\n",
       "count  5044.000000\n",
       "mean     10.236915\n",
       "std      10.598077\n",
       "min       1.000000\n",
       "25%       4.000000\n",
       "50%       7.000000\n",
       "75%      13.000000\n",
       "90%      22.000000\n",
       "95%      29.000000\n",
       "99%      50.000000\n",
       "max     142.000000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mcu.hist(column=\"words\", bins=60)\n",
    "pd.DataFrame(mcu[\"words\"]).describe(percentiles = DESCRIBE_PERCENTILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset  Preprocessing <a name=\"preprocessing\"></a>\n",
    "\n",
    "Based on the analysis above,  it is observed that median number of lines a character will speak is 4.  In other words, most characters don't have enough examples to train a classifier on.  So, to solve this problem, the dataset is limited to characters who speak more than 150 lines.  The cells below do this restriction, show which characters will be predicted, and create the dataset `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is main character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TONY STARK</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THOR</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STEVE ROGERS</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRUCE BANNER</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETER QUILL</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROCKET</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATASHA</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEPPER POTTS</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOKI</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              is main character\n",
       "TONY STARK                 True\n",
       "THOR                       True\n",
       "STEVE ROGERS               True\n",
       "BRUCE BANNER               True\n",
       "PETER QUILL                True\n",
       "ROCKET                     True\n",
       "NATASHA                    True\n",
       "PEPPER POTTS               True\n",
       "LOKI                       True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_line_count = 150\n",
    "\n",
    "is_main_character = mcu[\"character\"].value_counts() > min_line_count\n",
    "is_main_character = is_main_character.rename(\"is main character\", axis=0)\n",
    "\n",
    "main_character_rows = is_main_character[mcu[\"character\"]]\n",
    "main_character_rows = main_character_rows.reset_index(drop=True)\n",
    "\n",
    "mcu_partial = mcu[main_character_rows]\n",
    "\n",
    "pd.DataFrame(is_main_character)[is_main_character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Got it.', 'And terrifying.', 'What’s the delta rate?',\n",
       "        'This is beyond you, metal man. Loki will face Asgardian justice. ',\n",
       "        'He was kidding.', 'Was he married?',\n",
       "        'Is this about the Avengers?  Which I know nothing about.',\n",
       "        'Oh, sure, okayyyy, Quill.', 'Can I ask a few back?',\n",
       "        'Stark, are you seeing this? '], dtype='<U606'),\n",
       " array(['BRUCE BANNER', 'PEPPER POTTS', 'TONY STARK', 'THOR', 'NATASHA',\n",
       "        'STEVE ROGERS', 'PEPPER POTTS', 'ROCKET', 'TONY STARK',\n",
       "        'STEVE ROGERS'], dtype='<U12'))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mcu_partial[\"character\"].to_numpy().astype(str)\n",
    "X = mcu_partial[\"line\"].to_numpy().astype(str)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=RANDOM_SEED)\n",
    "\n",
    "X[0:10], y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models <a name=\"models\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True)\n",
    "score_method = \"balanced_accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "stem_count_vectorizer = StemCountVectorizer()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_jobs=-1, random_state=RANDOM_SEED)\n",
    "svm_classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_params = {'vect__binary': [True, False],\n",
    "               'vect__stop_words': [None, 'english', stopwords.words('english')],\n",
    "              'vect__ngram_range': [(1,1), (1,2), (1,3)]}\n",
    "\n",
    "tfidf_params = {'tfidf__norm': ['l1', 'l2'],\n",
    "              'tfidf__use_idf': [True, False]}\n",
    "\n",
    "nb_params = {'clf__alpha': [1, 1e-1, 1e-2, 1e-3],\n",
    "             'clf__fit_prior': [True, False]}\n",
    "\n",
    "rf_params = {'clf__criterion': [\"gini\", \"entropy\"],\n",
    "             'clf__max_depth': [None, 7, 8, 9, 10 ,11 ,12],\n",
    "             'clf__max_features': [None, \"sqrt\", \"log2\"],\n",
    "             'clf__class_weight': [None, 'balanced']}\n",
    "\n",
    "svm_params = {'clf__C': [1e-2, 1e-1, 0, 1, 10, 100],\n",
    "              'clf__kernel': ['linear', 'poly', 'rbf'],\n",
    "              'clf__degree': [2,3,4,5,6],\n",
    "              'clf__gamma': ['scale', 'auto'],\n",
    "              'clf__class_weight': [None, 'balanced']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 (Naive Bayes, no TFIDF, no stemming) <a name=\"model1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1,\n",
       " 'clf__fit_prior': False,\n",
       " 'vect__binary': True,\n",
       " 'vect__ngram_range': (1, 3),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1 = Pipeline([('vect', count_vectorizer), \n",
    "                  ('clf', nb_classifier)])\n",
    "\n",
    "parameters1 = {**count_params, **nb_params}\n",
    "\n",
    "grid1 = GridSearchCV(pipe1, parameters1, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid1.fit(X,y)\n",
    "\n",
    "grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Pipeline([('vect', CountVectorizer(binary=True, ngram_range = (1,3), stop_words = stopwords.words('english'))),\n",
    "                  ('clf', MultinomialNB(alpha=0.1, fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (Naive Bayes, TFIDF, no stemming) <a name=\"model2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2232 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed:   42.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1,\n",
       " 'clf__fit_prior': False,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__binary': False,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = Pipeline([('vect', count_vectorizer),\n",
    "                  ('tfidf', tfidf_transformer),\n",
    "                  ('clf', nb_classifier)])\n",
    "\n",
    "parameters2 = {**count_params, **tfidf_params, **nb_params}\n",
    "\n",
    "grid2 = GridSearchCV(pipe2, parameters2, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid2.fit(X,y)\n",
    "\n",
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Pipeline([('vect', CountVectorizer(binary=False, ngram_range=(1,2), stop_words=stopwords.words('english'))),\n",
    "                  ('tfidf', TfidfTransformer(norm='l2', use_idf=True)),\n",
    "                  ('clf', MultinomialNB(alpha=0.1, fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 (Naive Bayes, no TFIDF,  stemming) <a name=\"model3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 24.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1,\n",
       " 'clf__fit_prior': False,\n",
       " 'vect__binary': False,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3 = Pipeline([('vect', stem_count_vectorizer),\n",
    "                  ('clf', nb_classifier)])\n",
    "\n",
    "parameters3 = {**count_params, **nb_params}\n",
    "\n",
    "grid3 = GridSearchCV(pipe3, parameters3, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid3.fit(X,y)\n",
    "\n",
    "grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Pipeline([('vect', StemCountVectorizer(binary=False, ngram_range = (1,1), stop_words = None)),\n",
    "                  ('clf', MultinomialNB(alpha=0.1, fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 (Naive Bayes, TFIDF, stemming) <a name=\"model4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 67.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 85.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 95.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01,\n",
       " 'clf__fit_prior': False,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__binary': False,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe4 = Pipeline([('vect', stem_count_vectorizer),\n",
    "                  ('tfidf', tfidf_transformer),\n",
    "                  ('clf', nb_classifier)])\n",
    "\n",
    "parameters4 = {**count_params, **tfidf_params, **nb_params}\n",
    "\n",
    "grid4 = GridSearchCV(pipe4, parameters4, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid4.fit(X,y)\n",
    "\n",
    "grid4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Pipeline([('vect', StemCountVectorizer(binary=False, ngram_range=(1,2), stop_words=None)),\n",
    "                  ('tfidf', TfidfTransformer(norm='l2', use_idf=True)),\n",
    "                  ('clf', MultinomialNB(alpha=0.01, fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 (Random Forest, no TFIDF, no stemming) <a name=\"model5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1512 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed: 51.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 55.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7560 out of 7560 | elapsed: 56.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__class_weight': 'balanced',\n",
       " 'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 'sqrt',\n",
       " 'vect__binary': False,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5 = Pipeline([('vect', count_vectorizer), \n",
    "                  ('clf', rf_classifier)])\n",
    "\n",
    "parameters5 = {**count_params, **rf_params}\n",
    "\n",
    "grid5 = GridSearchCV(pipe5, parameters5, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid5.fit(X,y)\n",
    "\n",
    "grid5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Pipeline([('vect', CountVectorizer(binary=False, ngram_range = (1,2), stop_words = stopwords.words('english'))),\n",
    "                  ('clf', RandomForestClassifier(class_weight='balanced', criterion=\"gini\", max_depth=None, max_features=\"sqrt\",\n",
    "                                                 n_jobs=-1, random_state=RANDOM_SEED))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 (Random Forest, TFIDF, no stemming) <a name=\"model6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6048 candidates, totalling 30240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 38.4min\n",
      "/usr/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 8168 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9224 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10344 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11528 tasks      | elapsed: 75.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12776 tasks      | elapsed: 78.7min\n",
      "[Parallel(n_jobs=-1)]: Done 14088 tasks      | elapsed: 83.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15464 tasks      | elapsed: 110.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16904 tasks      | elapsed: 117.4min\n",
      "[Parallel(n_jobs=-1)]: Done 18408 tasks      | elapsed: 119.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19976 tasks      | elapsed: 123.3min\n",
      "[Parallel(n_jobs=-1)]: Done 21608 tasks      | elapsed: 126.1min\n",
      "[Parallel(n_jobs=-1)]: Done 23304 tasks      | elapsed: 154.3min\n",
      "[Parallel(n_jobs=-1)]: Done 25064 tasks      | elapsed: 161.5min\n",
      "[Parallel(n_jobs=-1)]: Done 26888 tasks      | elapsed: 166.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28776 tasks      | elapsed: 174.0min\n",
      "[Parallel(n_jobs=-1)]: Done 30240 out of 30240 | elapsed: 178.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__class_weight': 'balanced',\n",
       " 'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 'log2',\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__binary': True,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe6 = Pipeline([('vect', count_vectorizer),\n",
    "                  ('tfidf', tfidf_transformer),\n",
    "                  ('clf', rf_classifier)])\n",
    "\n",
    "parameters6 = {**count_params, **tfidf_params, **rf_params}\n",
    "\n",
    "grid6 = GridSearchCV(pipe6, parameters6, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid6.fit(X,y)\n",
    "\n",
    "grid6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Pipeline([('vect', CountVectorizer(binary=True, ngram_range=(1,1), stop_words=stopwords.words('english'))),\n",
    "                  ('tfidf', TfidfTransformer(norm='l2', use_idf=True)),\n",
    "                  ('clf', RandomForestClassifier(class_weight='balanced', criterion=\"gini\", max_depth=None, max_features=\"log2\",\n",
    "                                                 n_jobs=-1, random_state=RANDOM_SEED))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 (Random Forest, no TFIDF,  stemming) <a name=\"model7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1512 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 62.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 105.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 127.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed: 155.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed: 183.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed: 211.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed: 250.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 285.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7560 out of 7560 | elapsed: 300.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__class_weight': 'balanced',\n",
       " 'clf__criterion': 'gini',\n",
       " 'clf__max_depth': 12,\n",
       " 'clf__max_features': 'log2',\n",
       " 'vect__binary': True,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe7 = Pipeline([('vect', stem_count_vectorizer),\n",
    "                  ('clf', rf_classifier)])\n",
    "\n",
    "parameters7 = {**count_params, **rf_params}\n",
    "\n",
    "grid7 = GridSearchCV(pipe7, parameters7, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid7.fit(X,y)\n",
    "\n",
    "grid7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Pipeline([('vect', StemCountVectorizer(binary=True, ngram_range = (1,1), stop_words = stopwords.words('english'))),\n",
    "                  ('clf', RandomForestClassifier(class_weight='balanced', criterion=\"gini\", max_depth=12, max_features=\"log2\",\n",
    "                                                 n_jobs=-1, random_state=RANDOM_SEED))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8 (Random Forest, TFIDF, stemming) <a name=\"model8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** Model 8 was not trained using a GridSearch because the estimated training time was too large (19 hours).  Instead, the parameters were taken from model 6 (which is the same architecture minus stemming) and apply stemming.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Pipeline([('vect', StemCountVectorizer(binary=True, ngram_range=(1,1), stop_words=stopwords.words('english'))),\n",
    "                  ('tfidf', TfidfTransformer(norm='l2', use_idf=True)),\n",
    "                  ('clf', RandomForestClassifier(class_weight='balanced', criterion=\"gini\", max_depth=None, max_features=\"log2\",\n",
    "                                                 n_jobs=-1, random_state=RANDOM_SEED))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9 (SVM, no TFIDF, no stemming) <a name=\"model9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6480 candidates, totalling 32400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8168 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9224 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10344 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12629 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15450 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 17155 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 18531 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19971 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 21475 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 23043 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 24675 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 26371 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=-1)]: Done 28131 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done 29955 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=-1)]: Done 31843 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done 32400 out of 32400 | elapsed: 36.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1,\n",
       " 'clf__class_weight': 'balanced',\n",
       " 'clf__degree': 2,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'linear',\n",
       " 'vect__binary': True,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe9 = Pipeline([('vect', count_vectorizer), \n",
    "                  ('clf', svm_classifier)])\n",
    "\n",
    "parameters9 = {**count_params, **svm_params}\n",
    "\n",
    "grid9 = GridSearchCV(pipe9, parameters9, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid9.fit(X,y)\n",
    "\n",
    "grid9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = Pipeline([('vect', CountVectorizer(binary=True, ngram_range = (1,1), stop_words = stopwords.words('english'))),\n",
    "                  ('clf', SVC(C=0.1, class_weight='balanced', degree=2, gamma=\"scale\", kernel='linear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 10 (SVM, TFIDF, no stemming) <a name=\"model10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25920 candidates, totalling 129600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8168 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9224 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10344 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11528 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12776 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14088 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 15464 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16904 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18408 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19976 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 21608 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done 23304 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25064 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 26888 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 28776 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 30728 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=-1)]: Done 32744 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done 34824 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-1)]: Done 36968 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 39176 tasks      | elapsed: 47.0min\n",
      "[Parallel(n_jobs=-1)]: Done 41448 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done 45255 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=-1)]: Done 54855 tasks      | elapsed: 53.8min\n",
      "[Parallel(n_jobs=-1)]: Done 64711 tasks      | elapsed: 55.1min\n",
      "[Parallel(n_jobs=-1)]: Done 67407 tasks      | elapsed: 58.2min\n",
      "[Parallel(n_jobs=-1)]: Done 69999 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=-1)]: Done 72655 tasks      | elapsed: 64.5min\n",
      "[Parallel(n_jobs=-1)]: Done 75375 tasks      | elapsed: 67.6min\n",
      "[Parallel(n_jobs=-1)]: Done 78159 tasks      | elapsed: 71.2min\n",
      "[Parallel(n_jobs=-1)]: Done 81007 tasks      | elapsed: 75.0min\n",
      "[Parallel(n_jobs=-1)]: Done 83919 tasks      | elapsed: 78.8min\n",
      "[Parallel(n_jobs=-1)]: Done 86895 tasks      | elapsed: 82.8min\n",
      "[Parallel(n_jobs=-1)]: Done 89935 tasks      | elapsed: 86.7min\n",
      "[Parallel(n_jobs=-1)]: Done 93039 tasks      | elapsed: 90.4min\n",
      "[Parallel(n_jobs=-1)]: Done 96207 tasks      | elapsed: 94.5min\n",
      "[Parallel(n_jobs=-1)]: Done 99439 tasks      | elapsed: 98.7min\n",
      "[Parallel(n_jobs=-1)]: Done 102735 tasks      | elapsed: 103.2min\n",
      "[Parallel(n_jobs=-1)]: Done 106095 tasks      | elapsed: 107.8min\n",
      "[Parallel(n_jobs=-1)]: Done 109519 tasks      | elapsed: 112.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113007 tasks      | elapsed: 117.1min\n",
      "[Parallel(n_jobs=-1)]: Done 116559 tasks      | elapsed: 121.7min\n",
      "[Parallel(n_jobs=-1)]: Done 120175 tasks      | elapsed: 126.7min\n",
      "[Parallel(n_jobs=-1)]: Done 123855 tasks      | elapsed: 132.0min\n",
      "[Parallel(n_jobs=-1)]: Done 127599 tasks      | elapsed: 137.3min\n",
      "[Parallel(n_jobs=-1)]: Done 129600 out of 129600 | elapsed: 140.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__C': 100,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__degree': 2,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'linear',\n",
       " 'tfidf__norm': 'l1',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__binary': True,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe10 = Pipeline([('vect', count_vectorizer),\n",
    "                  ('tfidf', tfidf_transformer),\n",
    "                  ('clf', svm_classifier)])\n",
    "\n",
    "parameters10 = {**count_params, **tfidf_params, **svm_params}\n",
    "\n",
    "grid10 = GridSearchCV(pipe10, parameters10, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid10.fit(X,y)\n",
    "\n",
    "grid10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = Pipeline([('vect', CountVectorizer(binary=True, ngram_range = (1,2), stop_words = stopwords.words('english'))),\n",
    "                    ('tfidf', TfidfTransformer(norm='l1', use_idf=True)),\n",
    "                  ('clf', SVC(C=100, class_weight=None, degree=2, gamma=\"scale\", kernel='linear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 11 (SVM, no TFIDF,  stemming) <a name=\"model11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6480 candidates, totalling 32400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 52.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 69.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 88.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 109.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed: 131.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed: 157.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed: 184.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed: 214.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 246.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8168 tasks      | elapsed: 281.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9224 tasks      | elapsed: 318.1min\n",
      "[Parallel(n_jobs=-1)]: Done 10344 tasks      | elapsed: 357.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11528 tasks      | elapsed: 392.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12776 tasks      | elapsed: 426.0min\n",
      "[Parallel(n_jobs=-1)]: Done 14088 tasks      | elapsed: 460.7min\n",
      "[Parallel(n_jobs=-1)]: Done 15464 tasks      | elapsed: 497.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16904 tasks      | elapsed: 539.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18408 tasks      | elapsed: 592.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19976 tasks      | elapsed: 647.3min\n",
      "[Parallel(n_jobs=-1)]: Done 21608 tasks      | elapsed: 704.1min\n",
      "[Parallel(n_jobs=-1)]: Done 23304 tasks      | elapsed: 762.4min\n",
      "[Parallel(n_jobs=-1)]: Done 25064 tasks      | elapsed: 822.6min\n",
      "[Parallel(n_jobs=-1)]: Done 26888 tasks      | elapsed: 887.4min\n",
      "[Parallel(n_jobs=-1)]: Done 28776 tasks      | elapsed: 953.5min\n",
      "[Parallel(n_jobs=-1)]: Done 30728 tasks      | elapsed: 1020.2min\n",
      "[Parallel(n_jobs=-1)]: Done 32400 out of 32400 | elapsed: 1077.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1,\n",
       " 'clf__class_weight': 'balanced',\n",
       " 'clf__degree': 2,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'linear',\n",
       " 'vect__binary': True,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe11 = Pipeline([('vect', stem_count_vectorizer),\n",
    "                  ('clf', svm_classifier)])\n",
    "\n",
    "parameters11 = {**count_params, **svm_params}\n",
    "\n",
    "grid11 = GridSearchCV(pipe11, parameters11, cv=cross_validator, scoring=score_method, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid11.fit(X,y)\n",
    "\n",
    "grid11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11 = Pipeline([('vect', StemCountVectorizer(binary=True, ngram_range = (1,1), stop_words = stopwords.words('english'))),\n",
    "                    ('clf', SVC(C=0.1, class_weight='balanced', degree=2, gamma=\"scale\", kernel='linear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 12 (SVM, TFIDF, stemming) <a name=\"model12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** Model 12 was not trained using a GridSearch because the estimated training time was too large (90 hours).  Instead, the parameters were taken from model 10 (which is the same architecture minus stemming) and apply stemming.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = Pipeline([('vect', StemCountVectorizer(binary=True, ngram_range = (1,2), stop_words = stopwords.words('english'))),\n",
    "                    ('tfidf', TfidfTransformer(norm='l1', use_idf=True)),\n",
    "                  ('clf', SVC(C=100, class_weight=None, degree=2, gamma=\"scale\", kernel='linear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Scores (Balanced Accuracy) <a name=\"cvscores\"></a>\n",
    "\n",
    "To compare the models generated, the cell below performs cross validation using all of the data and reports the balanced accuracy of each model.  Balanced accuracy was used because the number of examples in each class is unequal.  \n",
    "\n",
    "The use of all of the data to estimate the balanced accuracies of the models poses a problem.  Because the hyperparameters were tunned using `GridSearchCV` on all of the data, the models are being evaluated on the same data that was used to construct them.  This could inflate their balanced accuracies higher than what might be observed on new, unseen data.  One solution to this problem, nested cross validation, was tried, but not used in the final models because it would be too computationally expensive to compute.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 1</th>\n",
       "      <th>model 2</th>\n",
       "      <th>model 3</th>\n",
       "      <th>model 4</th>\n",
       "      <th>model 5</th>\n",
       "      <th>model 6</th>\n",
       "      <th>model 7</th>\n",
       "      <th>model 8</th>\n",
       "      <th>model 9</th>\n",
       "      <th>model 10</th>\n",
       "      <th>model 11</th>\n",
       "      <th>model 12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.246431</td>\n",
       "      <td>0.262304</td>\n",
       "      <td>0.279967</td>\n",
       "      <td>0.298393</td>\n",
       "      <td>0.252171</td>\n",
       "      <td>0.241791</td>\n",
       "      <td>0.250181</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>0.228689</td>\n",
       "      <td>0.263049</td>\n",
       "      <td>0.238601</td>\n",
       "      <td>0.248601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.237293</td>\n",
       "      <td>0.240437</td>\n",
       "      <td>0.267587</td>\n",
       "      <td>0.256184</td>\n",
       "      <td>0.259556</td>\n",
       "      <td>0.228762</td>\n",
       "      <td>0.266336</td>\n",
       "      <td>0.247240</td>\n",
       "      <td>0.224073</td>\n",
       "      <td>0.238305</td>\n",
       "      <td>0.217469</td>\n",
       "      <td>0.242112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.262779</td>\n",
       "      <td>0.263440</td>\n",
       "      <td>0.260520</td>\n",
       "      <td>0.251073</td>\n",
       "      <td>0.250973</td>\n",
       "      <td>0.243186</td>\n",
       "      <td>0.212957</td>\n",
       "      <td>0.247465</td>\n",
       "      <td>0.239520</td>\n",
       "      <td>0.239635</td>\n",
       "      <td>0.241729</td>\n",
       "      <td>0.264450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290719</td>\n",
       "      <td>0.281750</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.273962</td>\n",
       "      <td>0.214795</td>\n",
       "      <td>0.243444</td>\n",
       "      <td>0.251129</td>\n",
       "      <td>0.242757</td>\n",
       "      <td>0.261810</td>\n",
       "      <td>0.240827</td>\n",
       "      <td>0.259531</td>\n",
       "      <td>0.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270262</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.234098</td>\n",
       "      <td>0.277709</td>\n",
       "      <td>0.230772</td>\n",
       "      <td>0.268181</td>\n",
       "      <td>0.225633</td>\n",
       "      <td>0.237491</td>\n",
       "      <td>0.218439</td>\n",
       "      <td>0.294691</td>\n",
       "      <td>0.228449</td>\n",
       "      <td>0.272966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.261497</td>\n",
       "      <td>0.269103</td>\n",
       "      <td>0.266614</td>\n",
       "      <td>0.271464</td>\n",
       "      <td>0.241653</td>\n",
       "      <td>0.245073</td>\n",
       "      <td>0.241247</td>\n",
       "      <td>0.244585</td>\n",
       "      <td>0.234506</td>\n",
       "      <td>0.255301</td>\n",
       "      <td>0.237156</td>\n",
       "      <td>0.257814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.018683</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.021704</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>0.011089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.290719</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.298393</td>\n",
       "      <td>0.259556</td>\n",
       "      <td>0.268181</td>\n",
       "      <td>0.266336</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>0.261810</td>\n",
       "      <td>0.294691</td>\n",
       "      <td>0.259531</td>\n",
       "      <td>0.272966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model 1   model 2   model 3   model 4   model 5   model 6   model 7  \\\n",
       "fold                                                                         \n",
       "0     0.246431  0.262304  0.279967  0.298393  0.252171  0.241791  0.250181   \n",
       "1     0.237293  0.240437  0.267587  0.256184  0.259556  0.228762  0.266336   \n",
       "2     0.262779  0.263440  0.260520  0.251073  0.250973  0.243186  0.212957   \n",
       "3     0.290719  0.281750  0.290900  0.273962  0.214795  0.243444  0.251129   \n",
       "4     0.270262  0.297584  0.234098  0.277709  0.230772  0.268181  0.225633   \n",
       "mean  0.261497  0.269103  0.266614  0.271464  0.241653  0.245073  0.241247   \n",
       "std   0.018683  0.019345  0.019306  0.016850  0.016479  0.012783  0.019241   \n",
       "max   0.290719  0.297584  0.290900  0.298393  0.259556  0.268181  0.266336   \n",
       "\n",
       "       model 8   model 9  model 10  model 11  model 12  \n",
       "fold                                                    \n",
       "0     0.247971  0.228689  0.263049  0.238601  0.248601  \n",
       "1     0.247240  0.224073  0.238305  0.217469  0.242112  \n",
       "2     0.247465  0.239520  0.239635  0.241729  0.264450  \n",
       "3     0.242757  0.261810  0.240827  0.259531  0.260938  \n",
       "4     0.237491  0.218439  0.294691  0.228449  0.272966  \n",
       "mean  0.244585  0.234506  0.255301  0.237156  0.257814  \n",
       "std   0.004012  0.015306  0.021704  0.014050  0.011089  \n",
       "max   0.247971  0.261810  0.294691  0.259531  0.272966  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12]\n",
    "\n",
    "cv_score_table = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(models)):\n",
    "    results = cross_val_score(models[i], X, y, cv=cross_validator, scoring=score_method, n_jobs=-1)\n",
    "    cv_score_table.insert(i, \"model \" + str(i+1), results, True)\n",
    "\n",
    "cv_score_table.index.name = \"fold\"\n",
    "cv_score_table.loc[\"mean\"] = cv_score_table.mean()\n",
    "cv_score_table.loc[\"std\"] = cv_score_table.std()\n",
    "cv_score_table.loc[\"max\"] = cv_score_table.max()\n",
    "\n",
    "cv_score_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model <a name=\"best-model\"></a>\n",
    "\n",
    "Based on the mean balanced accuracy from the table above, model 4 performs the best.  As a reminder, model 4 is a Naive Bayes Classifier that uses TF / IDF transformation and stemming.\n",
    "\n",
    "| Balanced Accuracy | Model 4  |\n",
    "| ----------------- | -------- |\n",
    "| mean              | 0.271464 |\n",
    "| max               | 0.298393 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Comparisons <a name=\"baselines\"></a>\n",
    "\n",
    "In order to further understand the performance of model 4, let's compare it to some baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Classifier <a name=\"majority-classifier\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MajorityClassifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.majority_label = None\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "        self.majority_label = unique_elements[np.argmax(counts_elements)]\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return np.array([self.majority_label] * X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Classifier <a name=\"random-classifier\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "class RandomClassifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.possible_labels = None\n",
    "        self.rng = default_rng(RANDOM_SEED)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.possible_labels = np.unique(y)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return self.rng.choice(self.possible_labels, X.shape[0], replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Model 4 <a name=\"comparison-model-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "      <th>majority</th>\n",
       "      <th>model 4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110231</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.298393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105197</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.256184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.122066</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.251073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136021</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.273962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112153</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.277709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117133</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.271464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010918</td>\n",
       "      <td>1.387779e-17</td>\n",
       "      <td>0.016850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.136021</td>\n",
       "      <td>1.111111e-01</td>\n",
       "      <td>0.298393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        random      majority   model 4\n",
       "fold                                  \n",
       "0     0.110231  1.111111e-01  0.298393\n",
       "1     0.105197  1.111111e-01  0.256184\n",
       "2     0.122066  1.111111e-01  0.251073\n",
       "3     0.136021  1.111111e-01  0.273962\n",
       "4     0.112153  1.111111e-01  0.277709\n",
       "mean  0.117133  1.111111e-01  0.271464\n",
       "std   0.010918  1.387779e-17  0.016850\n",
       "max   0.136021  1.111111e-01  0.298393"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [RandomClassifier(), MajorityClassifier(), model4]\n",
    "\n",
    "cv_score_table = pd.DataFrame()\n",
    "column_names = [\"random\", \"majority\", \"model 4\"]\n",
    "\n",
    "for i in range(0,len(models)):\n",
    "    results = cross_val_score(models[i], X, y, cv=cross_validator, scoring=score_method, n_jobs=-1)\n",
    "    cv_score_table.insert(i, column_names[i], results, True)\n",
    "\n",
    "cv_score_table.index.name = \"fold\"\n",
    "cv_score_table.loc[\"mean\"] = cv_score_table.mean()\n",
    "cv_score_table.loc[\"std\"] = cv_score_table.std()\n",
    "cv_score_table.loc[\"max\"] = cv_score_table.max()\n",
    "\n",
    "cv_score_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen above that model 4 out performes both a random classifier and a majority classifier with over double the balanced accuracy.  This means that even though performance is poor, model 4 is correclty using Naive Bayes to classify some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix <a name=\"confusion-matrix\"></a>\n",
    "\n",
    "Below is a confusion matrix generated by training the best model, model 4 on a subset of the data.  This yields a more accurate balanced accuracy than reported above because the model here is being tested using data it was not trained with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_accuracy: 0.2945764345872786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot legend</th>\n",
       "      <th># of examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TONY STARK</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THOR</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STEVE ROGERS</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUCE BANNER</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PETER QUILL</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROCKET</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NATASHA</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PEPPER POTTS</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LOKI</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    plot legend  # of examples\n",
       "0    TONY STARK            645\n",
       "1          THOR            479\n",
       "2  STEVE ROGERS            260\n",
       "3  BRUCE BANNER            258\n",
       "4   PETER QUILL            228\n",
       "5        ROCKET            198\n",
       "6       NATASHA            179\n",
       "7  PEPPER POTTS            172\n",
       "8          LOKI            164"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "model4.fit(X_train,y_train)\n",
    "yhat = model4.predict(X_test)\n",
    "\n",
    "print(\"balanced_accuracy:\", metrics.balanced_accuracy_score(y_test, yhat))\n",
    "\n",
    "main_characters = pd.DataFrame(is_main_character)[is_main_character].index.values\n",
    "\n",
    "metrics.plot_confusion_matrix(model4, X_test, y_test, labels = main_characters, display_labels = np.arange(9),\n",
    "                             values_format = 'd', cmap=plt.cm.Blues)\n",
    "\n",
    "line_counts = pd.DataFrame(mcu_partial[\"character\"].value_counts())[\"character\"]\n",
    "table = pd.DataFrame({\"plot legend\": main_characters, \"# of examples\": line_counts})\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printed above, it can be shown that a random split of the data can yield a balanced accuracy similar to the one reported by cross validation.\n",
    "\n",
    "In the matrix above, the diagonal elements (elements for which model 4 correctly predicts the character) are darker than those surrounding them.  This indicates that the model is correctly classifying some examples.  It can also be seen that there is a general gradient from light to dark closer to the upper left corner.  This is most likely because the characters indexed in that corner have more training examples than the others.  The total number of examples in the dataset for each character can be seen in the legend table.\n",
    "\n",
    "This gradient suggests that there may be a bias in the model towards classes with more training examples.  The plot below explores this question with learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves <a name=\"learning-curves\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x20a79c53430>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwU9f348dc7FwkEEoQaQSQBpCIIREAQBQSxiFr1S6sVpF6/KmqLVq1WPL7Wr/1i1XpXW6TWehRF633w9agS7wNQEIOAiBwBRI0SEsi5ef/+mNnN7GY3B+wkC/t+PtjHzs58Zvad2eXz/sxnZj8jqooxxpjkldLeARhjjGlflgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVki2IOIyNUicn97x9EeRKSDiKwQkf1aud7/ichZTSx/UET+d/cj3DuIyHgRKWnvOOJBRIpFZHwctjNERN6LQ0gJyxJBGxKRdSKyVUQ6eeadKyJFLVlfVW9U1XN9iKtIRKpEpEJEykTkLREZHO/32U0zgLdU9evWrKSqx6nqQwAicraIvLMrby4iY939UyEiO0REPa8rRKR3xH4MPka766uIHOhOXy8itSJS7j5Wi8g9ItLD837jRaQ+Ylsv7Ers8SQiJ4vIUhHZLiLficjrIlLgLrteRP7VvhE2UNVBqloUh+18CmwTkRN3P6rEZImg7aUBv23vIKKYqarZQDegCHikfcNp5HzaMSZVfVtVs919NMidnRucp6ob3HkzPfOyVfX9GJt8XFU7A/sAU4D9gCXeZABsjthWu1ZEbiJ7GPgdkAP0Af4K1LdnXG1kHs53cK9kiaDt/Rm4XERyoy0UkbtEZKPb4loiImM9y0ItLhF5WURmRqy7TER+5k4PEJHXROR7EVklIr9oSXCqWgfMBwZ6tjtSRN4XkW0issVtvWa4y+4Vkdsi4nhBRC5xp3uKyFMi8q2IfCUiF0dsd7H7t24Vkdtj7JPeQD/gQ/d1HzeWFPf1/SLyjaf8vzzvX+QedR0MzAFGu63rbZ636CoiL7mt8w9FpF9L9lU8qGqtqhYDpwHf4lSyrSIiJ4jIJ+5+3Cgi13uWFbhHI2eJyAa3FX+NZ3mWON1jP4jICuCwJt6qEPhKVV9XR7mqPqWqG0RkMnA1cJq7f5e5288RkX+435tNIvK/IpLqLjtbRN4VkTvcz3OtiBzhzt8oIt+Ip1vPjfOv4nT3Vbjr7icid7rxrxSRQz3l14nIMe709SLyhIg87H7OxSIywlN2mLsPy0Xk3yLyuIR3GRYBE0WkQ2s/nz2BJYK2txjnS3V5jOWLcP7D7QM8CvxbRDKjlHsUmBZ8ISIDgXzgJXG6nl5zy+zrlvuriAyKsp0wbgU/HfjAMzsAXAp0B0YDE4Ffu8seAqZ5KuXu7vLH3HkvAMuA/d35l4jIse66dwF3qWoXnIr+iRhhDQbWukkKVf0K2A4E/9OPBSrcyh5gHPCmdwOq+jlwAfC+27r2JuJpwP8AXYE1wOym9pEfVDUAPIfzt7TWDuBMIBc4AbhQRP4roswY4CCcz+A6z776A86+7wccC8Q8nwJ8DAxwK+4JIpLtif9l4EacI51sVR3qLnoIqAMOxPm8JgHe7s1RwKc4R6KP4jRCDnPL/xK4x/s+wC+Aa3G+i9XA+25c3YEngaiNCddJ7vZzgeeBeyD0nX8GeBDn/91jOEdpIaq6CajF2Yd7HUsE7eM64CIR+VHkAlX9l6qWqmqdqt4GdCD6l+8ZoFBE8t3X04GnVbUa+CmwTlX/6W7nY+Ap4JQmYrrbbSVXADNxKsZgTEtU9QN3W+uA+4Cj3GUfAWU4FQzAVKBIVbfi/If+kareoKo1qroW+LtbBpz/WAeKSHdVrVBVb/LxygXKI+a9CRwlDSePn3Rf9wG64CSflnpaVT9yE808nES8q+52W7fbROTjVq67GaciCurp2da2WEd1qlqkqstVtd7tz34M9/Px+B9VrVTVZTj7JlhR/wKYrarfq+pG4O5Ywbmf33icpP4E8J3bSs+OVl5E8oDjgEtUdYeqfgPcQcPnD84Rxj/dRPg4cABwg6pWq+qrQA1OUgh6xv0+VuH8H6hS1Yc96x9KbO+o6gK37COefXA4Tpft3e4R2tPAR1HWL8f5Lu51LBG0A1X9DHgRmBW5TER+JyKfi3PSdhtOX2z3KNsoB16i4T/VVJxKDJwjg1HeSgQnUTR1xc3Fbis5EyeRPCkiQ9yYfiwiL4rI1yKyHafl543pIZzWG+5zsC8/n4jKDKf7IM9d/ivgx8BKEVkkIj+NEdsPQOeIeW/iVErjgLdwjrKOch9vq2pr+q29J6B3AlErtha6WFVz3cewVq67P/C95/Vmz7ZyVTXqEZOIjBKRheJ0v5XhHPlEfmdi/Y09gY2eZeubCtBtEPxCVX+Ec/QyDrgmRvF8IB3Y4vn878M5Sg3a6pmudN8jcl52E+WbKhspch9kikgazj7YpOEjcG6ksc7Atijz93iWCNrPH4DzcP7zA86VKcCVOK20rm7FXAZIjG08htMtMxrIAha68zcCb0ZUItmqemFzQbmtyrdxukgmubP/BqwE+rvdOFdHxPQv4GQRGQocDDzrieOriDg6q+rx7nt9oarTcCqGm3GSTyca+xTo6/6nDXoTpyIa706/AxyJkwjejNxA8M9r7u9vL2432onA27uw+qM4XR0HqGoOzrmQWN+ZSFtwWuFBvVv6pqq6CHgaOCQ4K6LIRpzum+6ez7+LqjbbRdnGtgD7i4h3n3n3CSLSE8gAVrVlYG3FEkE7UdU1OIeyF3tmd8bpT/0WSBOR63C6OWJZgNPqugGnbzbYCn4R+LGInCEi6e7jME+/cJPcxDIQKPbEtR2nH34AEJZQVLUE59zGI8BTqlrpLvoI2C4iV7onJVNF5BAROcx9n1+KyI/cuIMtrUBkPO72vwBGeuZ9gdMC/CXOZaXbcVqHPyd2ItgK9HL7hBOC+9kcjJPU96PpPu5YOgPfq2qViIwETm/Fuk8AV4lIVxHpBVzURKxjROQ8EdnXfT0Ap9892KW3FSgIni9S1S3Aq8BtItJFRFJEpJ+IRHZbtbf3cb53M0UkTUROxvNdc40H3nC7Xvc6lgja1w2AtwX8CvB/wGqcQ/Qqoh+iAuB+KZ8GjsFpFQbnl+O05qfi9Dt/jdPibuqKh3vcKzEqcCr0a1X1/9xll+NULuU4ffyPR1n/IZyTuqFLPN2+2BNxrzYBvgPux+nuApgMFLvveRcw1e37jeY+4IyIeW8Cpdpw6eabOC3hT2Js4w2c5Pa1iHwXo0xbOc39u7fhtOZLgeGqunkXtvVr4AYRKcc5/xTrpHs0/4PzXfsKp9Ju6hLdbTgV/3I39pdx+ulvcZf/230u9ZwfOROnJb0Cp4vvScB7iWy7U9Ua4Gc4XZXbcBoXL+IczQRNxznS2iuJ2o1pTByIyDicLqKCVvbPt3T7HXAq+IluS9MY34jIh8AcVf2nOD+unKuqo9s7Lr9YIjC7TUTScS7LW6aqN7R3PMa0lttdtQrnqDXY+u+bLI2OtOaLGBOb27+9GOeSxHPaORxjdtVBOF1q2cCXwCnJkgTAjgiMMSbp2cliY4xJcntc11D37t21oKDAl23v2LGDTp2iXcaeOBI9xkSPDyzGeLEY46OtYlyyZMl37g8BG1PVPeoxfPhw9cvChQt923a8JHqMiR6fqsUYLxZjfLRVjMBijVGvWteQMcYkOd8SgYg8IM4wsp/FWC4icreIrBGRT0WkteOyGGOMiQM/jwgexPnlaCzHAf3dxwyc8WyMMca0Md8Sgaq+RfhIipFOBh52u68+AHIl/O5Mxhhj2oCvvyMQ516mL6rqIVGWvQjcpKrvuK9fB65U1cVRys7AOWogLy9v+Pz5832Jt6Kiguzs3RmB2H+JHmOixwcWY7xYjPHRVjFOmDBhiaqOiLow1lnkeDyAAuCzGMteAsZ4Xr+OM+iWXTXUhESPMdHjU7UY48VijI9kv2qohPAxv3vhjJRpjDGmDbVnIngeONO9euhwoEz9Gttj3jwoKICUFOd53rzm1jDGmKTh2y+LReQxnJs5dBeREpw7cqUDqOocnJuqHI9zJ6yd+DVg2bx5MGMG7NzpvF6/Hs47Dyoq4Be/cJJDaiqIQH09VFU50yLOMu+0McbshXxLBOrcgrCp5Qr8xq/3D7nmmoYkEFRZCRdeCH/4A2RlQWYmZGUxVBW6dg2bR2Zmw3THjuGP7Gzn4Z3u1Ml5ZGY2JJLI5+DDGGMSwB431lCrbdgQfb4qHH20kxTcR8p338E334TNo6rKebRWSkp4Mon23LFjeILp1KnhuVOnhiTjmZe5ZQts2tRQNj3dn6Qyb56TRDdsgN69YfZsmD49/u+zt7D91Tq2vxLK3p8Ievd2uoMi9ezpHBF4KtFPvvqK8X36NC6r2pAQqqvDE4R3OvK1N6EE51dWQnl544Szc6fTNdWMwyNnZGSEJ5fIBBNMGJHT3oTjne7UCV5/Hf77v524oKE7rbLS6U7zHtFETKfU1DR0r0VZHnN6Txat+3HGDGfaKrfGbH8lnL0/EcyeHf6lA6fiu/FG58QxOBW9qtPS7tWr4XVwWbCCrq93HsHlwdfeZZHlIpfFogq1tdGTjOd55caNDMjOdhLSzp2Nk05wescOKC1tvI3qXbz3dmWlkwzOO6/JYuN2besNWpM0misTo+yR9fWQltZ4vZZsN3Kb4CT1QCB8Gzt3wllnwXXXOUeHkeebYnUbus+FlZXQuXP08pHrBM9xBaejbbOp9b3nybzbi1XWnc7ftAnefDP68qZeX3dd4+7anTvh0kudrtmMDOdIt6XP6elOzHszn4+g9v5EENxZLdmJIk6S8FNkkomcbmbZ1x99xIDDDmtdcvIuCwSchLBjR0MiiUwWM2fGjv+KK5qMcW1ZGX1zcpr/W6Ptj8h5keWbeo617Sjztm7fTq/OnWOXbe38p58mqkAABgwI/1yC097PJMqzikBNTfTPMtr60bbV2unmGjXe8kCUY+fd8+23cMIJu7ZuSkpDUvAkiVH19U4Xa1NJJCPDaRh06BC9jHd+8BHxPruUvILTzWmDI6i9PxGAs7MS5ZBzd08Up6Q4LcV4iqxIb7kl+rmV3r3hf/+3oVwUG957j76jo9zjO0b5mMtaW765+Z5laxYvptcI9weWsY7UYs2Plrg++ghKShqX7dULHngg+naasWz5csYPHtz0+7aVGMm6qLiY8QMGxE4k0RJOfT0cfzx8/XXj9/nRj+C++5yj1ro6JxHW1jZ+BJfV1cVe7k5v376drPT0hnl1dU5jp6IivGy05+B05NFenB2VktKQYNLSGieNL7904vDaudNp3FoiMHETmZxuvDF2d1pGRvPbysz0J854SU2F4FFLPNx0U/T9ddNNkJe3a9v8/PNdX7etrFkD+fmtX+/WW6PvrzvugClTml+/FUeKn7/7LnlHHBG7XFNHksHEFkwI1dVOAvI+qqvD5wfLRSaryMTmWb7h22/J79SpcWILvl65Mvp+iHUhzC6wRGAaa013mrH91Vq7u79ac5GBiNO1k6hU+erNN8kfNy702rsMgH79Yh+hx4klAhNdInWn7Qlsf7WO7S9HMJk19YPVWEfos2fHLQz7uawxxiSy6dNh7lynG07EeZ47164aMsaYpOLzEZQdERhjTJKzRGCMMUnOEoExxiQ5SwTGGJPkLBEYY0ySs0RgjDFJztdEICKTRWSViKwRkVlRlncVkWdE5FMR+UhEDvEzHmOMMY35lghEJBW4FzgOGAhME5GBEcWuBpaq6hDgTOAuv+IxxhgTnZ9HBCOBNaq6VlVrgPnAyRFlBgKvA6jqSqBARBJ8pC1jjNm7iPo0tK2InAJMVtVz3ddnAKNUdaanzI1ApqpeJiIjgffcMksitjUDmAGQl5c3fP78+b7EXFFRQXZ2ti/bjpdEjzHR4wOLMV4sxvhoqxgnTJiwRFVHRF2oqr48gFOB+z2vzwD+ElGmC/BPYCnwCLAIGNrUdocPH65+WbhwoW/bjpdEjzHR41O1GOPFYoyPtooRWKwx6lU/xxoqAQ7wvO4FbI5IQtuBcwBERICv3Icxxpg24uc5gkVAfxHpIyIZwFTgeW8BEcl1lwGcC7zlJgdjjDFtxLcjAlWtE5GZwCtAKvCAqhaLyAXu8jnAwcDDIhIAVgC/8iseY4wx0fk6DLWqLgAWRMyb45l+H+jvZwzGGGOaZr8sNsaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJsn5mghEZLKIrBKRNSIyK8ryHBF5QUSWiUixiJzjZzzGGGMa8y0RiEgqcC9wHDAQmCYiAyOK/QZYoapDgfHAbZ57GBtjjGkDfh4RjATWqOpaVa0B5gMnR5RRoLOICJANfA/U+RiTMcaYCKKq/mxY5BRgsqqe674+AxilqjM9ZToDzwMDgM7Aaar6UpRtzQBmAOTl5Q2fP3++LzFXVFSQnZ3ty7bjJdFjTPT4wGKMF4sxPtoqxgkTJixR1RFRF6qqLw/gVOB+z+szgL9ElDkFuAMQ4EDgK6BLU9sdPny4+mXhwoW+bTteEj3GRI9P1WKMF4sxPtoqRmCxxqhX/ewaKgEO8LzuBWyOKHMO8LQb5xo3EQzwMSZjjDER/EwEi4D+ItLHPQE8FacbyGsDMBFARPKAg4C1PsZkjDEmQppfG1bVOhGZCbwCpAIPqGqxiFzgLp8D/BF4UESW43QPXamq3/kVkzHGmMZ8SwQAqroAWBAxb45nejMwyc8YjDHGNM1+WWyMMUnOEoExxiQ5SwTGGJPkLBEYY0ySs0RgjDFJzhKBMcYkOUsExhiT5CwRGGNMkrNEYIwxSc4SgTHGJDlLBMYYk+QsERhjTJKzRGCMMUnOEoExxiQ5SwTGGJPkLBEYY0yS8zURiMhkEVklImtEZFaU5VeIyFL38ZmIBERkHz9jMsYYE863RCAiqcC9wHHAQGCaiAz0llHVP6tqoaoWAlcBb6rq937FZIwxpjE/jwhGAmtUda2q1gDzgZObKD8NeMzHeIwxxkQhqurPhkVOASar6rnu6zOAUao6M0rZjkAJcGC0IwIRmQHMAMjLyxs+f/58X2KuqKggOzvbl23HS6LHmOjxgcUYLxZjfLRVjBMmTFiiqiOiLlRVXx7AqcD9ntdnAH+JUfY04IWWbHf48OHql4ULF/q27XhJ9BgTPT5VizFeLMb4aKsYgcUao171s2uoBDjA87oXsDlG2alYt5AxxrQLPxPBIqC/iPQRkQycyv75yEIikgMcBTznYyzGGGNiSPNrw6paJyIzgVeAVOABVS0WkQvc5XPcolOAV1V1h1+xGGOMic23RACgqguABRHz5kS8fhB40M84jDHGxGa/LDbGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnK+XjxpjWqe2tpaSkhJycnL4/PPP2zucJlmM8RHvGDMzM+nVqxfp6ektXscSgTEJpKSkhM6dO9OtWze6dOnS3uE0qby8nM6dO7d3GE1KthhVldLSUkpKSujTp0+L17OuIWMSSFVVFd26dUNE2jsUswcSEbp160ZVVVWr1rNEYEyCsSRgdseufH8sERhjQkpLSyksLKSwsJD99tuP/fffP/S6pqamyXUXL17MxRdf3Ox7HHHEEfEK18RJixOBiGSJyEF+BmOMaaV586CgAFJSnOd583Zrc926dWPp0qUsXbqUCy64gEsvvTT0OiMjg7q6upjrjhgxgrvvvrvZ93jvvfd2K0a/NPW37e1alAhE5ERgKfCy+7pQRBoNKW2MaUPz5sGMGbB+Pag6zzNm7HYyiHT22Wdz2WWXMWHCBK688ko++ugjjjjiCMaMGcMRRxzBqlWrACgqKuKnP/0pANdffz3/7//9P8aPH0/fvn3DEkTwblxFRUWMHz+eU045hQEDBjB9+vTgjapYsGABAwYMYMyYMVx88cWh7XoVFxczcuRICgsLGTJkCF988QUADz/8MEOGDGHo0KGcd955AKxfv56JEycyZMgQJk6cyIYNG6L+bV9++SWTJ09m+PDhjB07lpUrV8Z1Xyaqll41dD3OPYiLAFR1qYgU+BKRMcZxySWwdGns5R98ANXV4fN27oRf/Qr+/vfo6xQWwp13tjqU1atX85///IfU1FS2b9/OW2+9RWVlJR9++CFXX301Tz31VKN1Vq5cycKFCykvL+eggw7iwgsvbHRJ4yeffEJxcTE9e/bkyCOP5N1332XEiBGcf/75vPXWW/Tp04dp06ZFjWnOnDn89re/Zfr06dTU1BAIBCguLmb27Nm8++67dO/enfXr1wMwc+ZMzjzzTM466yweeOABLr74Yp599tlGf9vEiROZM2cO/fv358MPP+TXv/41b7zxRqv3156mpYmgTlXL7CSWMQkkMgk0N383nHrqqaSmpgJQVlbGWWedxapVq0hNTaW2tjbqOieccAIdOnSgQ4cO7LvvvmzdupVevXqFlRk5cmRoXmFhIevWrSM7O5u+ffuGLn+cNm0ac+fObbT90aNHM3v2bEpKSvjZz35G//79eeONNzjllFPo3r07APvssw8A77//Pk8//TQAZ5xxBr///e8b/W0VFRW89957nHrqqaFl1T7sy0TU0kTwmYicDqSKSH/gYiAxO/qM2Vs013IvKHC6gyLl50NRUVxD6dSpU2j6v//7v5kwYQIPP/wwpaWljB8/Puo6HTp0CE2npqZG7YOPVibYPdSc008/nVGjRvHSSy9x7LHHcv/996OqLbpqxlsm+LfV19eTm5vL0qaOwvZSLT1ZfBEwCKgGHgXKgEuaW0lEJovIKhFZIyKzYpQZLyJLRaRYRN5saeDGJL3Zs6Fjx/B5HTs6831UVlbG/vvvD8CDDz4Y9+0PGDCAtWvXsm7dOgAef/zxqOXWrl1L3759ufjiiznppJP49NNPmThxIk888QSlpaUAfP/994BzpdL8+fMBmDdvHmPGjGm0vS5dutCnTx/+/e9/A86Ps5YtWxbvPy8hNZsIRCQVeF5Vr1HVw9zHtara5C8W3PXuBY4DBgLTRGRgRJlc4K/ASao6CDi10YaMMdFNnw5z5zpHACLO89y5znwf/f73v+eqq67iJz/5CYFAIO7bz8rK4q9//SuTJ09mzJgx5OXlkZOT06jc448/ziGHHEJhYSErV67kzDPPZNCgQVxzzTUcddRRDB06lKuvvhqAu+++m3/+858MGTKERx55hLvuuivqe8+bN49//OMfDB06lEGDBvHcc0lyK3VVbfaBc9P5nJaU9awzGnjF8/oq4KqIMr8G/rc12x0+fLj6ZeHChb5tO14SPcZEj081sWNcsWKFqqpu3769nSNpnp8xlpeXq6pqfX29XnjhhXr77bfv0naSdT8Gv0dewGKNUa+29BxBFbBcRF4DQjeZV9Wmfj2yP7DR87oEGBVR5sdAuogUAZ2Bu1T14cgNicgMYAZAXl4eRXHu/wyqqKjwbdvxkugxJnp8kNgx5uTkUF5eTiAQoLy8vL3DaZKfMd5zzz089thj1NTUMGTIEP7whz/s0nsl636sqqpq1XdctAUnZkTkrGjzVfWhJtY5FThWVc91X58BjFTVizxl7gFGABOBLOB94ARVXR1ruyNGjNDFixc3G/OuCF7XnMgSPcZEjw8SO8bPP/+cgw8+OOkGS/NLssYY/B55icgSVR0RrXyLjghU9SERycBpwQOsUtXo14w1KAEO8LzuBWyOUuY7Vd0B7BCRt4ChQMxEYIwxJr5a+svi8cAXOCd//wqsFpFxzay2COgvIn3cJDIV51yD13PAWBFJE5GOOF1HiT14uDHG7GVaeo7gNmCSqq4CEJEfA48Bw2OtoKp1IjITeAVIBR5Q1WIRucBdPkdVPxeRl4FPgXrgflX9bNf/HGOMMa3V0kSQHkwCAKq6WkSavf2Nqi4AFkTMmxPx+s/An1sYhzHGmDhr6Q/KFovIP9wff40Xkb8DS/wMzBjTPr7++mumTp1Kv379GDhwIMcffzyrVyfeabsHH3yQmTNnAs64Qw8/3OiCQ9avX88hhxzS5HbWrVvHo48+Gnrd0uG09yYtTQQXAsU4Q0v8FlgBXOBXUMaYlpm3fB4FdxaQ8j8pFNxZwLzluzfyqKoyZcoUxo8fz5dffsmKFSu48cYb2bp1a1g5P35ItjsuuOACzjzzzF1aNzIRtHQ47bbm5z5vaSJIw7nG/2eqOgW4G6ff3xjTTuYtn8eMF2awvmw9irK+bD0zXpixW8lg4cKFpKenc8EFDe28wsJCxo4dS1FRERMmTOD0009n8ODBVFVVcc455zB48GAOPfRQFi5cCEQfHnrHjh2ccMIJDB06lEMOOaTRsBH19fUUFBSwbdu20LwDDzyQrVu38sILLzBq1CgOPfRQjjnmmEZJCZxhr2+99VYAlixZwtChQxk9ejR/94zCum7dOsaOHcuwYcMYNmxY6L4Is2bN4u2336awsJA77rgjbDjt77//nv/6r/9iyJAhHH744Xz66aeh94s1zHZQIBDg7LPP5pBDDmHw4MHccccdAKxZs4ZjjjmGoUOHMmzYMNauXYuqcsUVV4TKBvdP5D4PBAJcccUVHHbYYQwZMoT77ruvlZ9wdC09R/A6cAxQ4b7OAl4F7FZDxvjkkpcvYenXsQdA+6DkA6oD4aNj7qzdya+e+xV/XxJ9GOrC/Qq5c3Lswew+++wzhg+PeQ0IH330EZ999hl9+vThxhtvBGD58uWsXLmSSZMmsXr16qjDQy9YsICePXvy0ksvAc54RV4pKSmcfPLJPPPMM5xzzjl8+OGHFBQUkJeXx5gxY/jggw8QEe6//35uueUWbrvttpgxnnPOOfzlL3/hqKOO4re//W1o/r777strr71GZmYmX3zxBdOmTWPx4sXcdNNN3Hrrrbz44osAYT/E+sMf/sChhx7Ks88+yxtvvMGZZ54ZGpSuuWG2ly5dyqZNm/jsM+f6l2CSmz59OuEhgBwAACAASURBVLNmzWLKlClUVVVRVlbG008/zdKlS1m2bBnfffcdhx12GOPGjWu0z+fOnUtOTg6LFi2iurqaI488kkmTJrXqRvXRtPSIIFNVg0kAd7pjE+WNMT6LTALNzY+HkSNHhiqd999/nzPOOANwBorLz89n9erVjB49mhtvvJGbb76Z9evXk5WVxeDBg/nPf/7DlVdeydtvvx117KDTTjst1BKeP38+p512GgAlJSUce+yxDB48mD//+c8UFxfHjK+srIxt27Zx1FFHATB16tTQstraWs477zwGDx7MqaeeyooVK5r9e995553Q33j00UdTWloaSmLBYba7d+8eGmbbq2/fvqxdu5aLLrqIl19+mS5dulBeXs6mTZuYMmUKAJmZmXTs2JF33nmHadOmkZqaSl5eHkcddRSLFi1qtM9fffVVHn74YQoLCxk1ahSlpaWhG/LsjpYeEewQkWGq+jGAiIwAKnf73Y0xMTXVcgcouLOA9WWNh6HOz8mn6OyiXXrPQYMG8eSTT8Zc7h2OOtaoBNGGhz766KNZsmQJCxYs4KqrrmLSpEkce+yxnH/++QDccMMNnHjiiaxZs4Zvv/2WZ599lmuvvRaAiy66iMsuu4yTTjqJoqIirr/++pjxaRPDUN9xxx3k5eWxbNky6uvryczMbG53RP0bg9tvbpjtrl27smzZMl555RXuvfdennjiCe6MMbR4UyM8RO7zv/zlLxx77LHNxt4aLT0iuAT4t4i87f76dz4wM66RGGNaZfbE2XRMDz8w75jekdkTd30Y6qOPPprq6uqwvvVFixbx5puNR4g/8sgjmefeFnP16tVs2LCBgw46KOrw0Js3b6Zjx4788pe/5PLLL+fjjz9m1KhRofshn3TSSYgIU6ZM4bLLLuPggw+mW7duQPiw1w89FHNUGwByc3PJycnhnXfeAeCJJ54ILSsrK6NHjx6kpKTwyCOPhE6+du7cOeZYP+PGjQv9jUVFRXTv3p0uXbq0aF9+99131NfX8/Of/5w//vGPfPzxx3Tp0oVevXqF7o5WXV3Nzp07GTduHI8//jiBQIBvv/2Wt956i5EjRzba5rHHHsvf/va30M2AVq9ezY4dOxqVa60mE4GIHCYi+6nqImAA8DhQh3Pv4q92+92NMbts+uDpzD1xLvk5+QhCfk4+c0+cy/TBuz4MtYjwzDPP8Nprr9GvXz8GDRrE9ddfT8+ePRuVPffccwkEAgwePJjTTjuNBx98kA4dOkQdHnr58uWhE8izZ88OtfYjnXbaafzrX/8KdQuBc2L21FNPZezYsaE7jzXln//8J7/5zW8YPXp0WKv/17/+NQ899BCHH344q1evDrW0hwwZQlpaGkOHDg2d0PW+9+LFixkyZAizZs1qNhF5bdq0ifHjx1NYWMjZZ5/Nn/70JwAeeeQR7r77boYMGcIRRxzB1q1bmTJlSug+y0cffTS33HIL++23X6NtnnvuuQwcOJBhw4ZxyCGHcP7550e94U+rxRqW1D1U+RjYx50ehzNW0M+BPwJPNrWuXw8bhnphe4fQpESPTzWxY7RhqOMrWWOM9zDUqar6vTt9GjBXVZ8CnhKR5LufmzHG7IWaO0eQKiLBZDEReMOzrKUnmo0xxiSw5irzx4A3ReQ7nKuE3gYQkQNx7ltsjDFmD9dkIlDV2SLyOtADeNXtZwLnSOKi2GsaY3ZVw38zY1pvV74/zXbvqOoHUeYl3ghUxuwFMjMzKS0tJSMjo71DMXsgVaW0tLRFv5Hwsn5+YxJIr169KCkpYdu2ba3+z9zWqqqqLMY4iHeMmZmZ9OrVq1XrWCIwJoGkp6fTp08fioqKOPTQQ9s7nCZZjPGRCDG29JfFu0REJovIKhFZIyKzoiwfLyJlIrLUfVznZzzGGGMa8+2IQERSce5x/BOcm9QvEpHnVTVypKe3VfWnfsVhjDGmaX4eEYwE1qjqWlWtwRmf6GQf388YY8wuEL8uVRORU4DJqnqu+/oMYJSqzvSUGQ88hXPEsBm4XFUbjTErIjOAGQB5eXnD58+f70vMFRUVZGdn+7LteEn0GBM9PrAY48VijI+2inHChAlLVHVE1IWxxp7Y3QdwKnC/5/UZwF8iynQBst3p44EvmtuujTW0sL1DaFKix6dqMcaLxRgfbRUjTYw15GfXUAlwgOd1L5xWvzcJbVf3hjequgBIF5Hmhxc0xhgTN34mgkVAfxHpIyIZwFTgeW8BEdlP3Ls8iMhIN55SH2MyxhgTwberhlS1TkRmAq/g3Oj+AVUtFpEL3OVzgFOAC0WkDmcso6nuIYwxxpg24usPytzungUR8+Z4pu8B7vEzBmOMMU3z9QdlxhhjEp8lAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCTnayIQkckiskpE1ojIrCbKHSYiARE5xc94jDHGNOZbIhCRVOBe4DhgIDBNRAbGKHczzi0tjTHGtDE/jwhGAmtUda2q1gDzgZOjlLsIeAr4xsdYjDHGxCB+3Sve7eaZrKrnuq/PAEap6kxPmf2BR4GjgX8AL6rqk1G2NQOYAZCXlzd8/vz5vsRcUVFBdna2L9uOl0SPMdHjA4sxXizG+GirGCdMmLBEVUdEW+bnzeslyrzIrHMncKWqBkSiFXdXUp0LzAUYMWKEjh8/Pl4xhikqKsKvbcdLoseY6PGBxRgvFmN8JEKMfiaCEuAAz+tewOaIMiOA+W4S6A4cLyJ1qvqsj3EZY4zx8DMRLAL6i0gfYBMwFTjdW0BV+wSnReRBnK4hSwLGGNOGfEsEqlonIjNxrgZKBR5Q1WIRucBdPsev9zbGGNNyfh4RoKoLgAUR86ImAFU9289YjDHGRGe/LDbGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJ+XpjGhGZDNyFc4ey+1X1pojlJwN/BOqBOuASVX3Hz5iMMaYtqCqKNvtcr/VU1FSg6kw39cjOyKZrVte4x+pbIhCRVOBe4Cc4N7JfJCLPq+oKT7HXgedVVUVkCPAEMMCvmIwxBlpeSXufg5VxoD5APe5zREWtqtRTT319PQigNPtcW1/L5u2bQUAQRARBAELTz616jj+/92e2lG+hd05vZk+czfTB0+O2P/w8IhgJrFHVtQAiMh84GQglAlWt8JTvhLN7jDFJancq6GiP2kAt67et3+VK2vscq5IWEVIkhTRJa7S8JVIkhewO2Y3m19XXUVlbyVOfP8UNb95AdaAagPVl65nxwgyAuCUDUfWn7hWRU4DJqnqu+/oMYJSqzowoNwX4E7AvcIKqvh9lWzOAGQB5eXnD58+f70vMFRUVZGc3/kASSaLHmOjxgcUYL83FqG67zlvHeCtx5582lG1lxRx6jiCemVU7q8jsmOnMa1m93CKqSk19DVX1VVQHqqmqr6IqUBV6XV1fHXpdFagKva6ub7yssraSWmrDtlUdqKZWa5uMIa9DHvMPb3ldOGHChCWqOiLaMj+PCKLt9kZZR1WfAZ4RkXE45wuOiVJmLjAXYMSIETp+/Pj4RuoqKirCr23HS6LHmOjxgcXYUk21tuvq61jy/hIGDB9AQAPU1dcRqHeeG23H/W8fbDkLwgurX+DW925lc/lmenbuyawjZ/GzgT+LW+y1gVoq6ypZumgp3fp3Y2fdTiprK6msq3SeayvZWbuTyjr32V3mnVdVW9Vonne91kpLSaNjekey0rLISs8iKy2LjlkdySKLA/Y5ILSsY3pHZ7lb5o9v/THq9r6p/iZu3xE/E0EJcIDndS9gc6zCqvqWiPQTke6q+p2PcRmTVLwnJSMfwco7+AhW6sHlsQhCQAPsrNtJiqSQIilkpGWQKZnNxvP0509z9etXhyrTTeWbuPy1y/ni+y84bP/DolbQkZV3tIrZW7a23tOa/qhl+ymsEg5Op2XRLasbmemZYZV4xzSnXGTlnZmWGZqOLJOemh71fYsXFTPosEEx43rgkwfYVL6p0fzeOb1b9oe1gJ+JYBHQX0T6AJuAqcDp3gIiciDwpXuyeBiQAZT6GJMxe7RGJyYjWumRj4AGnD7xGEKtdLdvO0VSSE9JD81rTlVdFduqtlFWVUZZdRnbqrY5r6vLnHlV7rzqhjKbtm8KHSUEVQequfuju2O+T0ZqhlMJB1vTbgXbMb0j3Tt2b6igvS3u9Cy2bdpGvwP7hVXWjVreaU4F3tI+/bY2a8wsfv/a78OOQjqmd2T2xNlxew/fEoGq1onITOAVnMtHH1DVYhG5wF0+B/g5cKaI1AKVwGnq10kLYxJIrG4XRQnUBwjUB9hasbWhQndb7t5ulkjBbpdgCz0tJY10cSr1puKoqKkIVd7BSt1bmW+r3taosi+rKmN79Xb0ndj/XTukdiAnM4fczFxyOuTQo3MPBnQfwFPbn4paXhCem/pco8o6My0zZmu6OcX1xQwaGLu1HW/NndSGxudJ6rWeiuqK0HkPRZ3P1z0HMqnvJKonVHP7+7ezpWLPu2oIVV0ALIiYN8czfTNws58xGOO34H/ygDa+nDCy6yXUSg9WCp52j/dqkzqtY0ftjrBulw50iJoAVJXKukp+qPoh1AqPbJ2HKnJ3WbDs9urtBDQQ829LS0kjp4NbmWfm0D2rO/269iM3M5ea0hoO7HsguZm5ocreW/FnpWdF3eYHJR9E7ero2bknw3sOb9W+3xXBo6lYFTYQ6kpr0QlrGqZTUlJIISV0pOV9pKakkoL77M4TEUpSSuiV0yvsqiTv+RQR4bLRl/G7I37n2z7xNREYsyeKbK0HK25vpV4TqAmr1J9f9Tx3vH8HWyq20CO7B5eOvpSTDjopais9QzKiVujebpYV21ewZf2W8JZ5sLVe3bjVHtYnHiFFUhoq6Q5Ohd47pzc5mTmhSt5bkQcr89wOuXRM7xizy6R4UTGDhre+tR2tqyMrLYtZY2aF9n/kD66iVdTeVjXSkFS9ren6eufHWt6KOyXFrZwjKuWmHt4KOtZzU0deTUmRFDqmd9yldePFEoHZ60VW7KrKjpodUfvUa+trG50kVdXwVlrwunG3Un9m5TNct/C6UMW2uWIz175xLVvKtzB0v6GhVnhZldsSry5r1M1SVlVGVaAqPPBPw1+GKmr3uUfnHjEr8q6ZXUOvszOyd7mSao3gfvZW3sHXqm4lLjCp3ySq6qoaEmfnHlx2+GVM6jeJiuqKRq3qVEklNbVxazpWJe2dtzltM/269gsrYxqzRGD2SJHdL94TprX1tdQGahtd0hjse62prwl1TaRKathhfGZaZqjSrNd6yqrKKK0s5YfKHyitLOX7yu8bnnc689/e8HajFnl1oJrbP7i9UdzZGdlhXSgHdj2woWWe1VCZb1u/jcIhhaFlXTp0ITUl1fd9Gq0yD+sm8ezHUN82gBDWyg6ecE5LSSM1JdWpzFNSQxX1zJEzuXjUxY0qbj8qar/3297AEoFJCC25tLG2vpa6QF2ja9VDJ9doOGEabDl6L2msrqumtLKUr3Z8xQ9bfghV5t7KPfgIVv6x+s+z0rLo1rEb+2Tt02S3zAvTXgh1yXTp0KXFJz2LtxczaL/WdbtEXk3kPUmpDbW4+9Swz4LzUlJSQhV2mqSRlpIWqszTUtLC+q1TJIVNqZvou0/fsL5ss2eyRGB8EesEaqA+QG2g1qnUPSdPA/WBsF+EBqWkhPexB0+aApRVl4VV2pGVurclX7qzlB21Oxo2/EnDpCB0zepKtyynYu/XtR8jeo4IVfTB+cHnfbL2CTsROvLvI6Oe/Ny/8/4M6zGsxfvLe62/qlJZW9moW8UpHHwKr8yDlXVaShoZqRmhStz7HFmZe+e1luC8l9nz2adoWiTa5Y7BCjzUYg/UUhOoYc33a8KuivFW8JFXUwT72Wvra8Nb5ju/b1SpB7tiSitL+aHqh6i/YgXITMsMq7z7dO0TVpHv2LSDwsGFoYo+p0PObnUfxDr5+bvRv2Nn7c6wbpXIyjw4L7JbRUTo0qFLWCUeWXF7K3RrjZvdYYnAhHi7YR5d/ig3vHkDm8s3h07mnXjQieErKI1OoApCZmomFbUVYS10b8v8+6qGLpngo7ymPGpMgpCbmRuqtPt07cPwnsNDLfNQhe9pvce6bDGouLqYQb1id7tES3qhfvIoJvWbRE2ghtvev40t5Vvo2bknV4+9mlMHnhqqxINdVd6K21uZR1bkX6R8wY86/ajJv8OYeLFEkGS8v0CtDdRSVVdFVV0VNYEa6rUeEeGFVS9w7cJrqapzrmLZXL6ZaxdeS+nOUgp7FDb0o0fpX9+6fSvl75XH7DfPTM1kn44NlXhBbkGjitz7nJuZu1ut9ajDBGs95dXlMVvRwStVgl0swT7yyJa593HZ6Mu4bPRluxynMe3JEsFeSFXDWvdVdVVU11VTHagmUN9w8lPEOalaXVdNyfYSNpRtYH3Zem5///ZQEgiqqqviT+/+qdF75Wbmhirt/Jx8CtIK6Ne7X9RKvVvHbmSlZe1yN0asSr2pH6MHK+/01PTQ8AlpKWn07NyzyWvGjUkmlgj2YGFX1Hha98HWeLB/PkVS+KHqBzaVb3Iq+23rWVe2jvXb1rOhbAPf7vy2xe/55KlPhlrvuZm5jU4WNjeAVjCumF0vTQwwErwUMViZBx+xfhQU60qWVEmlc4fOLf6bjdnbWSJIcJFdOXX1dazftj6sKwcIjU2zqXwTG7Y7lf36betZX+Y8dtbuDG1TEHp27kl+bj4/6fsT8nPzyc/NpyCngN45vfnJIz+JeRXM6ANGh82LVqmHTpDGEHaiOCWD9NT0UFdMU7/0NMb4wxJBAmhpV86O2h18Uf4FX375JRvLNjqVvFvZb9q+Keya98zUTHrn9iY/J58jex9JQU5BqMLv1bkXHdI6xIzn90f+nln/mRV2FUxmWiaXHn6p83N9j8j+9FRJpVtWtyb7063rxZjEYomgDbWkK+e7Hd+xqXwTG8s3UlLm9NsHu3FKK90Rupc6T10zu1KQW8Cw/YYxZcCUsFZ9XnZezFZ0oD5ATaDGGeVSA40G0vpp/58iCLe8dwubtm+iV5deXD/+eqYdMq3ZSn1Vyipfbq5tjPGPJYI4a+6qnNpALVsqtlCyvYSN2zc2nKR1W/beVniKpDhdODn5TD5wMvk5+aR8l8LYEWPpndObLh26NHp/VSWgzo+2gtf6e4e2Df4IKCM1g07pnchIbeiaCQ4FICJcNOoiLhp1UVvuOmNMO7FEsAuideUEK/tAfYCKmgo2lm1k4/aNYS379WXr2VS+Kaz/PDMtk/wcp8tmbP5YCnILyM/Jp3dubw7ocgAZqRlh7128qJiDuh9EoD7g9MVH3IhbENJT0slMyyQjNcPprnEreO+vS40xJsgSQQzBlnWs1v03O75xKvqyjaHWfbCy/77y+7BtBS+tHNFzBD/P+bnThZPrduF0ygurmIPDMATfu6auJjTEriChyyW9FX3kwF7GGNMaviYCEZkM3IVzh7L7VfWmiOXTgSvdlxXAhaq6LN5xzFs+j2tev4YNZRsa3d3HW+kG1LnypqquymnVb3da8xu3bwxV+hu2b2BD2Yaw6+xTJIX9O+9Pfm4+xx14XKhVn5+bT35Oftilit6KPlAfcMa/iRgrPSM1g05pjbtt0lLS2Jy6mfzc/HjvImNMEvMtEYhIKnAv8BOcG9kvEpHnVXWFp9hXwFGq+oOIHAfMBUbFM455y+cx44UZocsn15et57znz6N0Zylje49l3bZ1oQp+xdoVbFu7jY1lG9lcsTmsCycrLYv8nHz65PZhfMF458dTbqu+V5deoS4cbyUfvD6+vLo8uE9IkzTSUxu6btJTnWvig5W9XSZpjGlrfh4RjATWqOpaABGZD5wMhBKBqr7nKf8B0CveQVzz+jVh19ADVNZVcunLl1JP+LXuOek59Ovej5H7j2x0bf2+nfZFRMIq+uCJ2JpATagLJ03cE7EdOjXqtgmODmmMMYlE/LpXvIicAkxW1XPd12cAo1R1ZozylwMDguUjls0AZgDk5eUNnz9/fovjOPrNoxvGYo9wbp9z6ZnZkx6ZPeiR2YOU6hQ6dHSur48cvz04amRTt6trCxUVFWRnZ7fJe+2KRI8PLMZ4sRjjo61inDBhwhJVHRFtmZ9HBNFqxqg1sohMAH4FjIm2XFXn4nQbMWLECB0/fnyLg+i9tDfry9Y3mt+zc0+uOP6KsCtuvlr6FT8e9mM6pHVodMWN99LK9lRUVERr/v62lujxgcUYLxZjfCRCjH4mghLgAM/rXsDmyEIiMgS4HzhOVUvjHcTsibPDzhGA099/3bjr6NG5R1jXzebUzRR0LYh3CMYYk9D8TASLgP4i0gfYBEwFTvcWEJHewNPAGaq62o8gglcHxbpqyBhjkp1viUBV60RkJvAKzuWjD6hqsYhc4C6fA1wHdAP+6na51MXqw9od0wdPt4rfGGNi8PV3BKq6AFgQMW+OZ/pcoNHJYWOMMW3HLlo3xpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpxvYw35RUS+BRqPGREf3YHvfNp2vCR6jIkeH1iM8WIxxkdbxZivqj+KtmCPSwR+EpHFfvygLZ4SPcZEjw8sxnixGOMjEWK0riFjjElylgiMMSbJWSIIN7e9A2iBRI8x0eMDizFeLMb4aPcY7RyBMcYkOTsiMMaYJGeJwBhjklzSJAIROUBEForI5yJSLCK/dedfLyKbRGSp+zjes85VIrJGRFaJyLFtFOc6EVnuxrLYnbePiLwmIl+4z13bK0YROcizr5aKyHYRuaS996OIPCAi34jIZ555rd5vIjLc3f9rRORuieO9SWPE+GcRWSkin4rIMyKS684vEJFKz/6c41mnrWNs9WfrV4wx4nvcE9s6EVnqzm+vfRirrkmo72MYVU2KB9ADGOZOdwZWAwOB64HLo5QfCCwDOgB9gC+B1DaIcx3QPWLeLcAsd3oWcHN7xuiJKxX4Gshv7/0IjAOGAZ/tzn4DPgJG49zN+v9wbqHqZ4yTgDR3+mZPjAXechHbaesYW/3Z+hVjtPgilt8GXNfO+zBWXZNQ30fvI2mOCFR1i6p+7E6XA58D+zexysnAfFWtVtWvgDXASP8jjRnLQ+70Q8B/eea3Z4wTgS9VtalferdJjKr6FvB9lPdu8X4TkR5AF1V9X53/hQ971vElRlV9VVXr3Jcf4NzbO6b2iLEJbb4fm4rPbS3/AnisqW20wT6MVdck1PfRK2kSgZeIFACHAh+6s2a6h+YPeA7X9gc2elYroenEES8KvCoiS0RkhjsvT1W3gPMlA/Zt5xiDphL+ny6R9iO0fr/t705Hzm8r/w+n1RfUR0Q+EZE3RWSsO6+9YmzNZ9teMY4FtqrqF5557boPI+qahP0+Jl0iEJFs4CngElXdDvwN6AcUAltwDi3BORSL1BbX2h6pqsOA44DfiMi4Jsq2V4yISAZwEvBvd1ai7cemxIqpPffnNUAdMM+dtQXoraqHApcBj4pIl3aKsbWfbXvtx2mEN0zadR9GqWtiFo0RT5vtx6RKBCKSjvPBzFPVpwFUdauqBlS1Hvg7Dd0WJcABntV7AZv9jlFVN7vP3wDPuPFsdQ8Tg4e137RnjK7jgI9Vdasbb0LtR1dr91sJ4V0zbRKriJwF/BSY7nYB4HYTlLrTS3D6jX/cHjHuwmfb5jGKSBrwM+BxT9zttg+j1TUk8PcxaRKB23/4D+BzVb3dM7+Hp9gUIHg1wvPAVBHpICJ9gP44J278jLGTiHQOTuOcSPzMjeUst9hZwHPtFaNHWOsrkfajR6v2m3u4Xi4ih7vflzM96/hCRCYDVwInqepOz/wfiUiqO93XjXFtO8XYqs+2PWIEjgFWqmqoK6W99mGsuoZE/j76cQY6ER/AGJzDqk+Bpe7jeOARYLk7/3mgh2eda3BaEavw6Wx9RIx9ca4eWAYUA9e487sBrwNfuM/7tFeM7nt2BEqBHM+8dt2POElpC1CL05L61a7sN2AETkX3JXAP7q/vfYxxDU7/cPA7Occt+3P3O7AM+Bg4sR1jbPVn61eM0eJz5z8IXBBRtr32Yay6JqG+j96HDTFhjDFJLmm6howxxkRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAJCQR6eYZNfJrCR/9MqOZdUeIyN0teI/34hdx+xORs0XknvaOw+x50to7AGOiUecXoYXgDIMMVKjqrcHlIpKmDYO1Ra67GFjcgvc4Ij7RGrNnsyMCs8cQkQdF5HYRWQjcLCIjReQ9d1Cx90TkILfceBF50Z2+3h0orUhE1orIxZ7tVXjKF4nIk+LcG2Ce+0tOROR4d9474owH/2KUuFLFua/AIndgtvPd+ZeJyAPu9GAR+UxEOjYR99ki8qyIvCAiX4nITHcbn4jIByKyj1uuSETudNf9TEQajebq/qr2KTemRSJypDv/KM+R1SfBX7Kb5GZHBGZP82PgGFUNiDOA2DhVrRORY4AbcX5NGmkAMAFnbPhVIvI3Va2NKHMoMAhnLJd3gSPFuTHQfe57fCUisYY3/hVQpqqHiUgH4F0ReRW4EygSkSk4vxw9X1V3isjKJuI+xI0lE+dXx1eq6qEicgfOEAN3uuU6qeoR4gxK+IC7ntddwB2q+o6I9AZeAQ4GLgd+o6rvijMoWlWMv8kkEUsEZk/zb1UNuNM5wEMi0h/nJ/3pMdZ5SVWrgWoR+QbII3x4X3DGdikBEOcOVwVABc7YNF+5ZR4DZtDYJGCIiJziiau/8WtqhwAAAbBJREFUmzzOxhlq4D5VfbcFcS9UZwz7chEpA15w5y8HhnjKPQbO+Pwi0kXcO5t5HAMMlIYbWnVxW//vAreLyDzgafWMzWOSlyUCs6fZ4Zn+I07FOUWccd+LYqxT7ZkOEP17H61MS28LKMBFqvpKlGX9cRJKT8+8puL2xlHveV0fEXfk2DCRr1OA0apaGTH/JhF5CWfsmw9E5BhVXRntjzLJw84RmD1ZDrDJnT7bh+2vBPq6lTXAaTHKvQJcKM7Qw4jIj8UZSTYHp4tmHNAt4ohhd+M+zX2vMTjdUmURy18FZgZfiEjwxHs/VV2uqjfjnFAfsIvvb/YilgjMnuwW4E8i8i7O/ZPjym1N/xp4WUTeAbYCkRUuwP3ACuBjcW6qfh9O6/0O4K+quhrnPMJNIrJvnOL+wb38dY677UgXAyPck9crgAvc+Ze4J5iXAZWE3xHNJCkbfdSYJohItqpWuFcR3Qt8oap3tHNMRTg3k2/2ElljWsKOCIxp2nnuyeNinC6d+9o5HmPizo4IjDEmydkRgTHGJDlLBMYYk+QsERhjTJKzRGCMMUnOEoExxiS5/w83bMeTxXA/CgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "title = \"Naive Bayes (with TFIDF and Stemming)\"\n",
    "\n",
    "plot_learning_curve(model4, title, X, y, cv=cross_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen above that there is a great difference in balanced accuracy between the training and cross-validation (testing) sets.  Not only is this observed, but it can also be observed that as the number of training examples increases, the cross-validation scores are slowly increasing.  This suggests that in relationship to the number of training examples, the scores have not yet converged, and that **more data would most likely increase the accuracy of model 4.**\n",
    "\n",
    "It is hypothesized that all the models perform between 20-30% because they do not have enough data to understand the complexity of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions  <a name=\"conclusions\"></a>\n",
    "\n",
    "## Project Improvements <a name=\"project-improvements\"></a>\n",
    "\n",
    "Given more time on the project, one thing I would like to explore is the performance of these 12 models given more data to train with.  The dataset, after limiting to characters with more than 150 lines, is only comprised of 2583 examples, which average about 10 words each.  The character with the most examples, Tony Stark, only has 645 lines.  By including the rest of the scripts released on Script Slug, and possibly transcripts of all 21 MCU movies, model performance could be greatly increased.\n",
    "\n",
    "Another aspect of the project that could be improved is the training time of the models.  The GridSearches peformed could be limited with a better understanding of each parameter, and could thus allow for quicker training times and maybe even nested cross validation.\n",
    "\n",
    "Finally, the project could benefit from the exploration of Word2Vec or neural networks.  These techniques have shown to be effective on very complex problems.\n",
    "\n",
    "## Takeaways <a name=\"takeaways\"></a>\n",
    "\n",
    "In this project I learned a lot about NLP techniques, as well as learned about models I hadn't been exposed to before. New to me were the concepts of turning a document into a word count vector, stemming, TF / IDF transformations, and stop words.  As far as models go, this was also the first time that I got to create a Naive Bayes, SVM, and Random Forest model.  I feel like I know a lot more about ML now than when I started this project!  Using Scikit-learn in this context also helped establish a set of skills which I can apply to other projects. \n",
    "\n",
    "## Moving Forward <a name=\"moving-forward\"></a>\n",
    "\n",
    "Moving forward, I would like to continue to explore the models and techniques used in this project.  I believe that what hindered my progress through this project was a lack of knowledge about which parameters are most significant to a model's success.  Although I read and learned about what each parameter does, I was unsure about which would have the biggest change on a model.  This is why I performed such vast grid searches.  I almost wonder if my time would have been better exploring more models and processing techniques, such as Word2Vec or neural networks, than waiting for these models to train.  \n",
    "\n",
    "I would also like to be more scientific and organized when I start my next project.  In this project, I began by just trying different things, whereas I would have liked to started with more of a plan.  I also would like to think about how and on what machine I train, so I can not waste time.  In future projects, I think having the experience I gained here will be a big help when constructing a more robust methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources <a name=\"sources\"></a>\n",
    "\n",
    "Ben-Hur, Asa. “CS345: Machine Learning Foundations and Practice.” GitHub, Colorado State University, 7 Dec. 2020, www.github.com/asabenhur/CS345. \n",
    "\n",
    "Charles R. Harris, et al. \"Array programming with NumPy\". Nature 585. 7825(2020): 357–362.\n",
    "\n",
    "Reback, J. et al. pandas-dev/pandas: Pandas 1.0.3. v1.0.3, Zenodo, 18 Mar. 2020.\n",
    "\n",
    "Lathrom, Matt. “Marvel Scripts.” Script Slug, www.scriptslug.com/scripts/category/marvel. \n",
    "\n",
    "Pedregosa, F. et al. \"Scikit-learn: Machine Learning in Python\". Journal of Machine Learning Research 12. (2011): 2825–2830.\n",
    "\n",
    "Shaikh, Javed. “Machine Learning, NLP: Text Classification Using Scikit-Learn, Python and NLTK.” Medium, Towards Data Science, 30 Oct. 2017, www.towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a. \n",
    "\n",
    "Starmer, Josh. “Naive Bayes, Clearly Explained!!!” YouTube, StatQuest with Josh Starmer, 3 June 2020, www.youtube.com/watch?v=O2L2Uv9pdDA. \n",
    "\n",
    "Starmer, Josh. “Support Vector Machines, Clearly Explained!!!” YouTube, StatQuest with Josh Starmer, 30 September 2019, www.youtube.com/watch?v=O2L2Uv9pdDA. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
