{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to CSV Process\n",
    "\n",
    "1. Load script `.txt` file.  Use [PDF Extractor](https://pdfextractor.com/) to convert any `.pdf`s to `.txt`s.\n",
    "2. Remove garbage rows\n",
    "3. Inspect rows removed\n",
    "4. Format lines\n",
    "5. Create `uppercase_unique_form.csv`\n",
    "6. Manually fill out `uppercase_unique_form.csv` columns `is_character_name` and `is_dialogue` in Excel or other `.csv` editor.\n",
    "7. Load `uppercase_unique.csv` and filter out rows\n",
    "8. Inspect rows removed\n",
    "9. Merge lines into best guesses for columns \"character\" and \"line\"\n",
    "10. Manually clean the \"line\" column by removing text that is not dialogue.  There will be a lot, so nearly every cell will have to be cleaned!\n",
    "\n",
    "\n",
    "See the script at the end of this notebook for an example of this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Garbage Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_regex_rows(df,string):\n",
    "    rows_to_remove = df[\"line\"].str.contains(string,case=True,regex=True)\n",
    "    print(\"Removed\",rows_to_remove.sum(),\"rows that match regex \\\"\" + string + \"\\\"\")\n",
    "    \n",
    "    return df[~rows_to_remove], df[rows_to_remove]\n",
    "\n",
    "def remove_whitespace_rows(df):\n",
    "    whitespace_rows = df[\"line\"].str.isspace()\n",
    "    print(whitespace_rows.sum(),\"whitespace rows removed\")\n",
    "    return df[~whitespace_rows], df[whitespace_rows]\n",
    "\n",
    "def remove_movie_text_rows(df):\n",
    "    \n",
    "    regex_strings = [\"INTERCUT\",\n",
    "                    \"CUT TO\",\n",
    "                    \"^THE END\",\n",
    "                    \"^INT\\.\",\n",
    "                    \"^EXT\\.\",\n",
    "                    \"CONTINUED\",\n",
    "                    \"^[0-9]+\\.$\",\n",
    "                    \"^\\([^\\(\\)]*\\)$\",\n",
    "                    \"\\(.*radio\\)\",\n",
    "                    \"\\(.*earpiece\\)\",\n",
    "                    \"\\(.*headset\\)\",\n",
    "                    \"\\(.*phone\\)\",\n",
    "                    \"\\(.*cell\\)\",\n",
    "                    \"\\(to .*\\)\",\n",
    "                    \"\\(in .*\\)\",\n",
    "                    \"\\(MORE\\)\",\n",
    "                    \"\\(angry\\)\",\n",
    "                    \"TIME CUT:\",\n",
    "                    \"TITLE:\",\n",
    "                    \"SLAM TO\",\n",
    "                    \"DISSOLVE TO\",\n",
    "                    \"FADE\",\n",
    "                    \"BEST ADAPTED SCREENPLAY\",\n",
    "                    \"MARVEL\",\n",
    "                    \"© Marvel\",\n",
    "                    \"FADE TO BLACK\",\n",
    "                    \"CUE MUSIC\",\n",
    "                    \"BLUE DRAFT 05/20/16\",\n",
    "                    \"SALMON #2\",\n",
    "                    \"../../..\",\n",
    "                    \"OMITTED\",\n",
    "                    \"MAIN TITLE\",\n",
    "                    \"[A-J][0-9]+\",\n",
    "                    \"[0-9]+[A-J]\",\n",
    "                    \"\\*\",\n",
    "                    \"\\(.*:\\)\",\n",
    "                    \"^\\(beat\\)$\",\n",
    "                    \"\\(re:.*\\)\"]\n",
    "    \n",
    "    removed_rows = pd.DataFrame()\n",
    "    \n",
    "    for regex_string in regex_strings:\n",
    "        df, new_rows_to_remove = remove_regex_rows(df,regex_string)\n",
    "        \n",
    "        removed_rows = pd.concat([removed_rows, new_rows_to_remove])\n",
    "    \n",
    "    return df, removed_rows\n",
    "\n",
    "\n",
    "def remove_page_number_rows(df):\n",
    "    page_rows = df[\"line\"].str.isnumeric()\n",
    "    print(page_rows.sum(),\"page number rows removed\")\n",
    "    \n",
    "    return df[~page_rows], df[page_rows]\n",
    "\n",
    "def remove_garbage_rows(df):\n",
    "    df, whitespace_rows = remove_whitespace_rows(df)\n",
    "    df, page_number_rows = remove_page_number_rows(df)\n",
    "    df, movie_text_rows = remove_movie_text_rows(df)\n",
    "    \n",
    "    garbage_rows = pd.concat([whitespace_rows, page_number_rows, movie_text_rows], \n",
    "                            keys = [\"whitespace\",\"page_numbers\",\"movie_text\"])\n",
    "    \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(garbage_rows.shape[0],\"total rows removed\\n\")\n",
    "    \n",
    "    return df, garbage_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Character Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_regex(df,string):\n",
    "    print(\"Removed\",df[\"line\"].str.count(string).sum(),\"occurences of regex \\\"\" + string + \"\\\"\")\n",
    "    df[\"line\"] = df[\"line\"].str.replace(string,\"\",case=True,regex=True)\n",
    "\n",
    "def remove_leading_trailing_whitespace(df):\n",
    "    df[\"line\"] = df[\"line\"].str.replace(\"[ \\t]+$\",\"\")\n",
    "    df[\"line\"] = df[\"line\"].str.replace(\"^[ \\t]+\",\"\")\n",
    "\n",
    "def format_lines(df):\n",
    "    remove_leading_trailing_whitespace(df)\n",
    "    \n",
    "    regex_strings = [\"\\(O\\.S\\)\",\n",
    "                    \"\\(V\\.O\\)\",\n",
    "                     \"\\(V\\.O\\.\\)\",\n",
    "                    \"\\(CONT.D\\)\",\n",
    "                    \"\\(cont.d\\)\",\n",
    "                    \"\\(O\\.S\\.\\)\",\n",
    "                    \"\\(ON.*\\)\",\n",
    "                    \"\\(OVER.*\\)\",\n",
    "                    \"\\(INTO.*\\)\",\n",
    "                    \"\\(HOLO\\)\",\n",
    "                    \"\\(ADR\\)\",\n",
    "                    \"\\(then\\)\",\n",
    "                    \" \\(RHODEY’S VOICE\\)\",\n",
    "                    \" \\(PRE-LAP\\)\"]\n",
    "    \n",
    "    for regex_string in regex_strings:\n",
    "        remove_regex(df, regex_string)\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    remove_leading_trailing_whitespace(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Non Dialogue Uppercase Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppercase_rows(df):\n",
    "    upper_lines = df[\"line\"].str.isupper()\n",
    "    \n",
    "    return df[upper_lines]\n",
    "\n",
    "def create_uppercase_unique_csv(df,script_name):\n",
    "    '''\n",
    "    Creates a csv file that is used for inspection of unique\n",
    "    lines that are all uppercase.  These lines are manually labeled\n",
    "    to be character names or dialogue.  The resulting table will be\n",
    "    used to delete rows that are neither character names nor dialogue.\n",
    "    '''\n",
    "    \n",
    "    upper_rows = uppercase_rows(df)\n",
    "    unique_upper_rows = pd.DataFrame(upper_rows.line.unique())\n",
    "\n",
    "    unique_upper_rows[\"words\"] = unique_upper_rows[0].str.split(\" \").str.len()\n",
    "    unique_upper_rows[\"is_character_name\"] = 0\n",
    "    unique_upper_rows[\"is_dialogue\"] = 0\n",
    "    sorted_unique_upper_rows = unique_upper_rows.sort_values(by=[\"words\"])\n",
    "    sorted_unique_upper_rows.to_csv(\"./uppercase forms/\" + script_name + \"_uppercase_unique_form.csv\",encoding='utf-8')\n",
    "    \n",
    "    print(\"Created \" + \"./uppercase forms/\" + script_name + \"_uppercase_unique_form.csv\\n\")\n",
    "    \n",
    "def remove_non_dialogue_upper_rows(df,upper_rows):\n",
    "    '''\n",
    "    Removes lines that are in all caps, and that are not dialogue or a character's name.\n",
    "    '''\n",
    "    unique_character_names = upper_rows[upper_rows[\"is_character_name\"]][\"line\"]\n",
    "    unique_dialogues = upper_rows[upper_rows[\"is_dialogue\"]][\"line\"]\n",
    "    \n",
    "    all_character_name_lines = df[df[\"line\"].isin(unique_character_names)]\n",
    "    all_dialogue_lines = df[df[\"line\"].isin(unique_dialogues)]\n",
    "    \n",
    "    print(df[\"line\"].str.isupper().sum(),\"total uppercase lines\")\n",
    "    print(all_character_name_lines.shape[0],\"uppercase character name lines\")\n",
    "    print(all_dialogue_lines.shape[0],\"uppercase dialogue lines\")\n",
    "    \n",
    "    unique_lines_to_remove = upper_rows[~(upper_rows[\"is_character_name\"]|upper_rows[\"is_dialogue\"])][\"line\"]\n",
    "    removed_lines = df[\"line\"].isin(unique_lines_to_remove)\n",
    "    print(removed_lines.sum(),\"uppercase lines removed\")\n",
    "    \n",
    "    return df[~removed_lines], df[removed_lines] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_character_name(string,character_names):\n",
    "    return string in character_names[\"line\"].tolist()\n",
    "    \n",
    "\n",
    "def merge_lines(df,character_names):\n",
    "    '''\n",
    "    Starts at a character name and merges all lines until the next character's name.\n",
    "    The result should be the best guess at columns \"character\" and \"line\".\n",
    "    This will merge in some screenplay text that is not dialogue, so the result will \n",
    "    have to be manually cleaned as the final step.\n",
    "    '''\n",
    "    merged_df = pd.DataFrame(columns=[\"character\",\"line\"])\n",
    "    \n",
    "    for i in range(0,df.shape[0]):\n",
    "        \n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        if is_character_name(row[\"line\"],character_names):\n",
    "            character = row[\"line\"]\n",
    "            line = \"\"\n",
    "            \n",
    "            j = i + 1\n",
    "            while(j < len(df) and (not is_character_name(df.iloc[j][\"line\"],character_names))):\n",
    "                line += df.iloc[j][\"line\"] + \" \"\n",
    "                j += 1\n",
    "            \n",
    "            new_row = {\"character\": character,\"line\": line}\n",
    "            \n",
    "            merged_df = merged_df.append(new_row,ignore_index=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 whitespace rows removed\n",
      "328 page number rows removed\n",
      "Removed 0 rows that match regex \"INTERCUT\"\n",
      "Removed 4 rows that match regex \"CUT TO\"\n",
      "Removed 1 rows that match regex \"^THE END\"\n",
      "Removed 80 rows that match regex \"^INT\\.\"\n",
      "Removed 115 rows that match regex \"^EXT\\.\"\n",
      "Removed 0 rows that match regex \"CONTINUED\"\n",
      "Removed 138 rows that match regex \"^[0-9]+\\.$\"\n",
      "Removed 128 rows that match regex \"^\\([^\\(\\)]*\\)$\"\n",
      "Removed 0 rows that match regex \"\\(.*radio\\)\"\n",
      "Removed 0 rows that match regex \"\\(.*earpiece\\)\"\n",
      "Removed 0 rows that match regex \"\\(.*headset\\)\"\n",
      "Removed 0 rows that match regex \"\\(.*phone\\)\"\n",
      "Removed 0 rows that match regex \"\\(.*cell\\)\"\n",
      "Removed 0 rows that match regex \"\\(to .*\\)\"\n",
      "Removed 0 rows that match regex \"\\(in .*\\)\"\n",
      "Removed 0 rows that match regex \"\\(MORE\\)\"\n",
      "Removed 0 rows that match regex \"\\(angry\\)\"\n",
      "Removed 0 rows that match regex \"TIME CUT:\"\n",
      "Removed 0 rows that match regex \"TITLE:\"\n",
      "Removed 0 rows that match regex \"SLAM TO\"\n",
      "Removed 0 rows that match regex \"DISSOLVE TO\"\n",
      "Removed 2 rows that match regex \"FADE\"\n",
      "Removed 0 rows that match regex \"BEST ADAPTED SCREENPLAY\"\n",
      "Removed 0 rows that match regex \"MARVEL\"\n",
      "Removed 0 rows that match regex \"© Marvel\"\n",
      "Removed 0 rows that match regex \"FADE TO BLACK\"\n",
      "Removed 0 rows that match regex \"CUE MUSIC\"\n",
      "Removed 0 rows that match regex \"BLUE DRAFT 05/20/16\"\n",
      "Removed 0 rows that match regex \"SALMON #2\"\n",
      "Removed 0 rows that match regex \"../../..\"\n",
      "Removed 22 rows that match regex \"OMITTED\"\n",
      "Removed 0 rows that match regex \"MAIN TITLE\"\n",
      "Removed 0 rows that match regex \"[A-J][0-9]+\"\n",
      "Removed 93 rows that match regex \"[0-9]+[A-J]\"\n",
      "Removed 0 rows that match regex \"\\*\"\n",
      "Removed 0 rows that match regex \"\\(.*:\\)\"\n",
      "Removed 0 rows that match regex \"^\\(beat\\)$\"\n",
      "Removed 0 rows that match regex \"\\(re:.*\\)\"\n",
      "-----------------------------------------\n",
      "1051 total rows removed\n",
      "\n",
      "Removed 0 occurences of regex \"\\(O\\.S\\)\"\n",
      "Removed 0 occurences of regex \"\\(V\\.O\\)\"\n",
      "Removed 8 occurences of regex \"\\(V\\.O\\.\\)\"\n",
      "Removed 146 occurences of regex \"\\(CONT.D\\)\"\n",
      "Removed 0 occurences of regex \"\\(cont.d\\)\"\n",
      "Removed 8 occurences of regex \"\\(O\\.S\\.\\)\"\n",
      "Removed 0 occurences of regex \"\\(ON.*\\)\"\n",
      "Removed 0 occurences of regex \"\\(OVER.*\\)\"\n",
      "Removed 0 occurences of regex \"\\(INTO.*\\)\"\n",
      "Removed 0 occurences of regex \"\\(HOLO\\)\"\n",
      "Removed 0 occurences of regex \"\\(ADR\\)\"\n",
      "Removed 0 occurences of regex \"\\(then\\)\"\n",
      "Removed 0 occurences of regex \" \\(RHODEY’S VOICE\\)\"\n",
      "Removed 0 occurences of regex \" \\(PRE-LAP\\)\"\n",
      "\n",
      "Created ./uppercase forms/thor_uppercase_unique_form.csv\n",
      "\n",
      "1098 total uppercase lines\n",
      "1026 uppercase character name lines\n",
      "15 uppercase dialogue lines\n",
      "57 uppercase lines removed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JANE</td>\n",
       "      <td>Hurry!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JANE</td>\n",
       "      <td>Oh-- watch your head.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELVIG</td>\n",
       "      <td>Thanks. So what's this \"anomaly\" of yours supposed to look like?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JANE</td>\n",
       "      <td>It's a little different each time. Once it looked like, I don't know, melted stars, pooling in a corner of the sky. But last week it was a rolling rainbow ribbon--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELVIG</td>\n",
       "      <td>Racing Àúround Orion?\" I've always said you should have been a poet.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character  \\\n",
       "0      JANE   \n",
       "1      JANE   \n",
       "2    SELVIG   \n",
       "3      JANE   \n",
       "4    SELVIG   \n",
       "\n",
       "                                                                                                                                                                   line  \n",
       "0                                                                                                                                                                Hurry!  \n",
       "1                                                                                                                                                 Oh-- watch your head.  \n",
       "2                                                                                                     Thanks. So what's this \"anomaly\" of yours supposed to look like?   \n",
       "3  It's a little different each time. Once it looked like, I don't know, melted stars, pooling in a corner of the sky. But last week it was a rolling rainbow ribbon--   \n",
       "4                                                                                                  Racing Àúround Orion?\" I've always said you should have been a poet.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thor = pd.read_csv(\"./script txts/thor-script-slug.txt\",sep=\"\\n\",header=None,names=[\"line\"])\n",
    "\n",
    "thor, garbage_rows = remove_garbage_rows(thor)\n",
    "format_lines(thor)\n",
    "\n",
    "thor[thor[\"line\"].str.contains(\"[^a-zA-Z\\d\\.,\\?! '’\\\"-…]\", regex=True)]\n",
    "\n",
    "create_uppercase_unique_csv(thor,\"thor\")\n",
    "filled_out_upper_rows = pd.read_csv(\"./uppercase results/thor_uppercase_unique.csv\",\n",
    "                                    names=[\"\",\"line\",\"words\",\"is_character_name\",\"is_dialogue\"],\n",
    "                                    dtype={\"line\":str, \"words\":int, \"is_character_name\":bool, \"is_dialogue\":bool},\n",
    "                                    index_col=0)\n",
    "\n",
    "thor, upper_removed_rows = remove_non_dialogue_upper_rows(thor, filled_out_upper_rows)\n",
    "removed_rows = pd.concat([garbage_rows,pd.concat([upper_removed_rows],keys=[\"\"])],keys=[\"garbage\",\"uppercase\"])\n",
    "\n",
    "unique_character_names = pd.DataFrame(filled_out_upper_rows[filled_out_upper_rows[\"is_character_name\"]][\"line\"])\n",
    "\n",
    "thor = merge_lines(thor, unique_character_names)\n",
    "thor.reindex(copy=False)\n",
    "\n",
    "thor.to_csv(\"./uncleaned/thor_uncleaned.csv\", index=False)\n",
    "\n",
    "thor = pd.read_csv(\"./cleaned/thor.csv\")\n",
    "\n",
    "thor.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
