import streamlit as st
import pandas as pd
import numpy as np
from joblib import load
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

from sklearn.feature_extraction.text import CountVectorizer
from nltk.stem import SnowballStemmer

from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf

CHARACTER_IMAGE_PATHS = {"TONY STARK": "./images/tony-stark.png",
                         "BRUCE BANNER": "./images/bruce-banner.png",
                         "PEPPER POTTS": "./images/pepper-potts.png",
                         "NATASHA ROMANOFF": "./images/natasha.png",
                         "LOKI": "./images/loki.png",
                         "STEVE ROGERS": "./images/steve-rogers.png",
                         "THOR": "./images/thor.png",
                         "NICK FURY": "./images/nick-fury.png",
                         "PETER PARKER": "./images/peter-parker.png",
                         "JAMES RHODES": "./images/james-rhodes.png"}

class StemCountVectorizer(CountVectorizer):
    def build_analyzer(self):
        analyzer = super(StemCountVectorizer, self).build_analyzer()

        return lambda document: (
        [SnowballStemmer('english', ignore_stopwords=True).stem(word) for word in analyzer(document)])

class Application():
    def __init__(self):
        self.input_string = None
        self.model = load('./production_model.joblib')
        self.model_predictions = load('./production_predictions.joblib')
        self.character_similarity = load('./character_similarity.joblib')
        self.main_characters = self.model_predictions["true character"].value_counts().index.to_numpy()

        self.prediction = None
        self.prediction_conf = None
        self.prediction_probs = None

        self.rank_table = None
        self.hierarchical_rank_table = None
        
        self.recalls = pd.read_csv("./production_recalls.csv")
        self.confusion_matrix = None

    def render_header(self):
        
        st.markdown('<style>.text{font-family: "IBM Plex Mono", monospace; white-space: pre;font-size: 0.8rem; overflow-x: auto;}</style>', unsafe_allow_html=True)
        
        st.title("Marvel Dialogue Classification")
        st.text("By Preston Dunton")
        st.text("")
        st.text("")
        
        st.text("This page presents a machine learning project on dialogue from Marvel's movies.  Below,\n"
                "you'll find an interactive interface for predictions, details about the model, metrics of\n"
                "the model's performance, insights into the Marvel Cinematic Universe (MCU), and\n"
                "interactive samples of the model's predictions.")
        st.markdown('<p class="text">For more about the project see its <a class="text" href="https://github.com/prestondunton/marvel-dialogue-nlp" target="_blank">GitHub repository</a>.  Feel free to contact me at\n<a class="text" href="mailto:preston.dunton@gmail.com">preston.dunton@gmail.com</a>.</p>', unsafe_allow_html=True)
        st.markdown('', unsafe_allow_html=True)
        
        st.text("")
        st.text("")

    def render_interactive_prediction(self):
        
        st.header("Interactive Prediction")
        st.text("Type in a line to see which character is predicted to say it!")
        
        self.input_string = st.text_input('Input Line', 'I am Iron Man.')
        
        self.prediction = self.model.predict([self.input_string])
        self.prediction_conf = self.model.predict_proba([self.input_string]).max()
        col1, col2, col3 = st.beta_columns(3)
        
        st.markdown('<style>.prediction{color: red; font-size: 24px; font-weight: bold}</style>', unsafe_allow_html=True)
        
        with col1:
            st.subheader("Prediction:")
            st.markdown('<p class="prediction">' + self.prediction[0].title() + '</p>', unsafe_allow_html=True)
        with col2:
            st.subheader("Confidence:")
            st.markdown('<p class="prediction">' + "{0:.3%}".format(self.prediction_conf) + '</p>', unsafe_allow_html=True)
        with col3:
            st.image(CHARACTER_IMAGE_PATHS[self.prediction[0]], width=200)
            
        self.render_probability_table()


    def render_probability_table(self):

        #st.subheader("Probability Table")

        vect = self.model.named_steps['vect']
        tokenizer = vect.build_tokenizer()
        prediction_array = tokenizer(self.input_string)
        prediction_array.append(self.input_string)

        probabilities = pd.DataFrame(self.model.predict_proba(prediction_array).transpose())
        probabilities.columns = prediction_array
        probabilities.columns = [*probabilities.columns[:-1], 'Combined Probability']
        probabilities.insert(0, "character", self.model.classes_)
        probabilities.set_index('character', inplace=True)
        probabilities.sort_values(by=['Combined Probability'], ascending=False, inplace=True)
        
        used_column_names = []
        column_names = probabilities.columns.to_numpy()
        for i in range(0,len(column_names)):
            while column_names[i] in used_column_names:
                column_names[i] = column_names[i] + " "
                
            used_column_names.append(column_names[i])
            
        probabilities.columns = column_names

        self.prediction_probs = probabilities
        
        st.dataframe(self.prediction_probs.style.background_gradient(cmap=plt.cm.Reds, high=0.35))
        
        st.text("The table above shows the probabilities the model predicts given a character the input.\n"
                "Each cell holds the probability of predicting its row's character given its column's\n"
                "word. In other words:")
        st.latex("cell(row, column)=P(character|word)")
        st.text("The final column represents the probability our model predicts a character given the\n"
                "entire input string together.  The character with the largest value in this column\n"
                "is our model's prediction.  One character words like 'I' and 'a' are removed because\n"
                "they don't provide any useful information to the model.  No other words are removed.")
        st.text("By clicking on the names of the columns, you can sort the table and see which\n"
                "character is most likely to say a word.")

    def render_about_the_model(self):
        st.header("About the Model")
        
        
        st.subheader("Implementation Details")
        st.markdown('<p class="text">This project uses <a href="https://scikit-learn.org/stable/" target="_blank">scikit-learn</a> to implement a <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" target="_blank">Naive Bayes Classifier</a>.  Hyperparameter\n'
                    'selection is done using cross validation (5 folds).  The model is also evaluated using\n'
                    'cross validation (100 folds).  With hyperparameter selection, this results in nested cross\n'
                    'validation.  Stop words, which are words that provide no value to predictions (I, you,\n'
                    'the, a, an, ...), are not removed from predictions.  Hyperparameter selection showed\n'
                    'better performance keeping all words rather than removing <a href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python/" target="_blank">NLTK\'s list of stop words</a>.\n'
                    'Words are stemmed using <a href="https://www.nltk.org/_modules/nltk/stem/snowball.html" target="_blank">NLTK\'s SnowballStemmer</a>.  Word counts are also transformed into\n'
                    'term frequencies using scikit-learn\'s implementation.</p>', unsafe_allow_html=True)
        st.markdown('<p class="text">To see the code for the model, see <a href="https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/Production%20Models.ipynb" target="_blank">this Jupyter Notebook</a>.</p>', unsafe_allow_html=True)
        
        st.subheader("Dataset Details")
        st.markdown('<p class="text">The dataset used was created for this project by parsing the Marvel released script /\n'
                    'online transcript for 18 movies.  See the <a href="https://github.com/prestondunton/marvel-dialogue-nlp" target="_blank">repository\'s README.md</a> for a table of which\n'
                    'movies are included and which are not, as well as more details.  If you spot an error\n'
                    'in the data, please contact me so I can fix it.</p>', unsafe_allow_html=True)
        st.markdown('<p class="text">To see an in depth analysis of the dataset, see <a href="https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/Dataset%20Analysis.ipynb" target="_blank">this Jupyter Notebook</a>.</p>', unsafe_allow_html=True)
        
        st.subheader("Why these characters?")
        st.markdown("<p class='text'>While the dataset contains the dialogue for all 652 character, most of which are just\n"
                "movie extras, trying to predict a large number of characters results in such poor\n"
                "performance that the model isn't useful or fun in any way.  The ten characters\n"
                "used are the top ten characters by number of lines in the dataset, number of words\n"
                "in the dataset, and number of movie appearances.</p>", unsafe_allow_html=True)
        st.markdown('<p class="text">For details on this dataset\'s creation and the calculations used to select these\n'
                    'characters, see <a href="https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/data/MCU.ipynb" target="_blank">this Jupyter Notebook</a>.</p>', unsafe_allow_html=True)

    def render_model_performance(self):
        st.header("Model Performance")
        
        st.markdown('<p class="text">To see the code for these metrics, and more metrics, see <a href="https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/Production%20Models.ipynb" target="_blank">this Jupyter Notebook</a></p>', unsafe_allow_html=True)

        self.render_confusion_matrix()
        self.render_recalls()
        self.render_accuracy_by_words()

        y = self.model_predictions['true character']
        yhat = self.model_predictions['predicted character']
        st.subheader("Model's Balanced Accuracy: {0:.3%}".format(metrics.balanced_accuracy_score(y, yhat)))
        
        st.text("The model's performance isn't great, but it's still fun to interact with!  Over the course\n"
                "of the project it's been shown that more data only results in marginal increases in\n"
                "performance.  Above, it's shown that accuracy increases as the number of words in a line\n"
                "increases.  In other words, it seems that spoken dialogue is too short to predict in\n"
                "this case.  The Naive Bayes classifier is a Bag of Words model, meaning that the order\n"
                "of the words is ignored.  By using a Word Embeddings model, which does not ignore the\n"
                "order of words, accuracy could possibly be increased.  Deep learning also might have\n"
                "success on this dataset.")
        
    def render_confusion_matrix(self):
        y = self.model_predictions['true character']
        yhat = self.model_predictions['predicted character']

        st.subheader("Confusion Matrix")
        
        st.text("The plot below summarizes the predictions of our model.  Each cell represents the\n"
                "proportion of all of a true character's examples that are predicted as a character.\n"
                "In other words, each row adds up to 1.0, and the cells can be seen as what percent of\n"
                "examples are predicted as a given character.")
        st.text("The diagonal elements represent examples that our model correctly predicts, as well as\n"
                "the recall for that character.")

        conf_matrix = pd.DataFrame(metrics.confusion_matrix(y, yhat, labels=self.main_characters))
        normalized_conf_matrix = conf_matrix.div(conf_matrix.sum(axis=1), axis=0)
        normalized_conf_matrix.columns = pd.Series(self.main_characters, name="Predicted Character")
        normalized_conf_matrix.index = pd.Series(self.main_characters, name="True Character")
        
        self.confusion_matrix = normalized_conf_matrix

        fig = plt.figure(figsize=(2, 2))
        fig, ax = plt.subplots()
        ax = sns.heatmap(normalized_conf_matrix, annot=True, fmt='.2f', cmap=plt.cm.Reds)

        st.pyplot(fig)
        
    def render_recalls(self):
        st.subheader("Accuracy by Character (Recall)")
        st.text("Given a line we'd like to predict from a given character, here's how often we can expect\n"
                "our model to be correct.")
        
        self.recalls.set_index("Unnamed: 0", drop=True, inplace=True)
        st.dataframe(self.recalls)
        
        
    def render_accuracy_by_words(self):
        
        st.subheader("Performance Vs. Words")
        
        st.text("Do examples with more words (longer examples) get classified correctly more often?\n"
                "Let's do a linear regression test.")
        
        def abline(intercept, slope, col):
            """Plot a line from slope and intercept"""
            axes = plt.gca()
            x_vals = np.array(axes.get_xlim())
            y_vals = intercept + slope * x_vals
            plt.plot(x_vals, y_vals, '-', color=col)
       
        regression_data = self.model_predictions.copy(deep=True)
        
        regression_data['words'] = regression_data['line'].str.split(" ").str.len()
        regression_data['correct_prediction'] = (regression_data['true character'] == regression_data['predicted character']).astype('int64')
        
        reg_model = smf.ols('regression_data["correct_prediction"] ~ regression_data["words"]', data=regression_data).fit()
        
        fig = plt.figure(figsize=(2, 2))
        fig, ax = plt.subplots()

        ax = plt.scatter(x = regression_data['words'].to_numpy(),
                y = regression_data['correct_prediction'].to_numpy(),
                color='black')

        abline(reg_model.params[0], reg_model.params[1], 'red')

        conf_pred_intervals = reg_model.get_prediction(regression_data['words']).summary_frame()

        plt.fill_between(regression_data['words'].to_numpy(), conf_pred_intervals['mean_ci_lower'], conf_pred_intervals['mean_ci_upper'], alpha=0.3, color='red')

        plt.grid()
        plt.ylim(-0.1,1.2)
        plt.title('Performance vs. Length of Words (with 95% CI Band)')
        plt.xlabel('words')
        plt.ylabel('accuracy')
        
        st.pyplot(fig)
        
        st.markdown("<p class=\"text\">Using a t test and a confidence level of 95% (α=0.05), we <text class=\"text\" style=\"font-weight: bold\">reject</text> the null hypothesis that\n"
                    "there is no relationship between the number of words in an example and our model's\n"
                    "performance on it (t=10.871, p&lt0.001).</p>", unsafe_allow_html=True)

        st.text("Having a longer line means that the change of a correct prediction increases.")

    def render_model_insights(self):
        st.header("MCU Insights")
        
        st.markdown('<p class="text">For the code used to infer these insights, see <a href="https://github.com/prestondunton/marvel-dialogue-nlp/blob/master/data/MCU.ipynb" target="_blank">this Jupyter Notebook</a>.</p>', unsafe_allow_html=True)
        
        st.subheader("Character Similarity")
        st.text("The similarity score used here is the dot product between the unit word count vectors of\n"
                "every word a character has ever said.  To get this score, we just count how many times a\n"
                "character has said every word, divide the vector by it's norm, and then do a dot product\n"
                "with another character's vector.")
        st.text("It should be noted that the confusion matrix above could also be interpreted as a measure\n"
                "of similarity.  Characters who are easily confused with each other could be seen as\n"
                "similar.  For example, Thor and Loki are easily confused with each other by the model,\n"
                "which makes sense because they are both Asgardian.")
        
        fig = plt.figure(figsize=(2, 2))
        fig, ax = plt.subplots()
        ax = sns.heatmap(self.character_similarity, annot=True, fmt='.2f', cmap=plt.cm.Reds)

        st.pyplot(fig)
        
        st.markdown('<p class="text" style="font-weight: bold;">Why are these similarity scores so high?</p>', unsafe_allow_html=True)
        st.markdown('<p class="text">The characters are most likely so similar with each other because they are all speaking\n'
                    'English, which like any language, is very structured and systematic.  According to <a href="https://www.youtube.com/watch?v=fCn8zs912OE" target="_blank">Michael\n'
                    'Steven\'s discussion</a> of Zipf\'s Law and the Pareto Distribution, the top 20% of words (words\n'
                    'like "the" "I" "he" "she") make up approximately 80% of all speech.</p>', unsafe_allow_html=True)  

        st.markdown('<p class="text" style="font-weight: bold;">Why is Peter Parker so unique compared to the other characters?</p>', unsafe_allow_html=True)
        
        st.text("Peter Parker only has 4 movie appearances, which is less than all the other characters\n"
                "(9, 10, 7, 10, 7, 7, 7, 6, 8).  However, this doesn't seem to have an effect on the mean,\n"
                "sum, and standard deviation of his word count vector. These statistics do not seem to be\n"
                "out of the ordinary compared to the other characters.  Furthermore, Peter Parker does not\n"
                "seem to have an unusual vocabulary size or number of words unique to himself.  ")

        st.text("Another hypothesis on why Peter Parker is so unique is his age.  He is much younger than\n"
                "all the other characters used, and therefore might talk about different topics, like high\n"
                "school (homecoming, field trips, homework, ...).")

        st.text("Finally, Peter Parker might be so unique because he's not part of the larger Avengers\n"
                "team.  The \"friendly neighborhood Spider-Man\" deals with much smaller problems than\n"
                "the other Avengers.  For example, the Avengers team might be more likely to deal with\n"
                "governments, aliens, SHIELD, and large scale enemies than Peter.  One counter argument to\n"
                "this hypothesis is Pepper Potts, who is also not part of the Avengers team and also has\n"
                "high similarity with the other characters.  However, her close interaction with Tony\n"
                "Stark might make her discuss these same issues when she speaks.  More evidence for this\n"
                "can be seen in the confusion matrix / recalls.  Peter Parker performs the highest out of\n"
                "any of the characters, which suggests that his dialogue style is the most identifiable\n"
                "or unique.")

        st.markdown("<p class=\"text\">The probable answer is that Peter Parker is so unique for all of the reasons mentioned\n"
                "above together. Peter Parker is arguably the most unique character in the MCU, which is\n"
                "why he is such a fan favorite.  If a trascript for <i>Spider-Man: Far Frome Home</i> was\n"
                    "completed and added to the dataset, it would be interesting to see how that affects this\n"
                    "similarity.</p>", unsafe_allow_html=True)
        
        st.subheader("Character Development")
        
        st.markdown("<p class='text'>An interesting extension of this project would be to explore the question: <p class='text' style='font-weight: bold'>Are there quantifiable differences between a character in different movies or written\n"
                    "under different authors?</p></p>", unsafe_allow_html=True)
        st.markdown("<p class='text'>One character that might be interesting to investigate is Thor.  Thor in <i>Thor</i>,\n"
                    "<i>Thor: The Dark World</i>, <i>The Avengers</i>, and <i>Avengers: Age of Ultron</i>, is very different from\n"
                    "Thor in <i>Thor: Ragnarok</i>, <i>Avengers: Infinity War</i>, and <i>Avengers: Endgame</i>.  <i>Thor: Ragnorak</i> is\n"
                    "a turning point for Thor, as he takes on a more comedic role than previously.</p>", unsafe_allow_html=True)
        st.markdown("<p class='text'>Though I have little experience in unsupervised learning, I wonder if clustering would\n"
                    "reveal any insights.  For example, if we did clustering with more than 10 clusters, would\n"
                    "the clusters be the characters in different movies?  Because the characters are so\n"
                    "similar, my guess is no.</p>", unsafe_allow_html=True)
        st.markdown("<p class='text'>Another way to try and answer this question is to use supervised leraning where the\n"
                    "labels are the same character under different movies.  By analyzing the performance of a\n"
                    "model on that dataset, it might indicate how cohesively the character is written.</p>", unsafe_allow_html=True)
        
    
    def render_model_predictions(self):
        st.header("Model Predictions")
        
        st.text("Use the multiselects to view how the model performed on lines from the movies.  These\n"
                "predictions were created using cross-validation (100 fold), so no example is predicted\n"
                "with a model that saw the example in training.")

        table = self.model_predictions
        table['correct prediction'] = table['true character'] == table['predicted character']
        table['correct prediction'] = table['correct prediction'].replace({0: 'No', 1: "Yes"})        

        true_character_filter = st.multiselect("True Character", list(self.main_characters), ["PETER PARKER"])
        pred_character_filter = st.multiselect("Predicted Character", list(self.main_characters), ["PETER PARKER"])
        movie_filter = st.multiselect("Movie", list(self.model_predictions['movie'].unique()), ['Spider-Man: Homecoming', "Captain America: Civil War"])
        
        if len(true_character_filter) == 0:
            true_character_filter = self.main_characters
        if len(pred_character_filter) == 0:
            pred_character_filter = self.main_characters
        if len(movie_filter) == 0:
            movie_filter = self.model_predictions['movie'].unique()
        
        st.table(table[table['true character'].isin(true_character_filter) &
                       table['predicted character'].isin(pred_character_filter) &
                       table['movie'].isin(movie_filter)])
        
    def render_app(self):
        st.set_page_config(page_title='Marvel Dialogue Classification', layout='centered', \
                           initial_sidebar_state='auto', page_icon="./images/marvel-favicon.png")

        self.render_header()
        
        st.image("./images/horizontal_line.png", use_column_width=True)
        self.render_interactive_prediction()

        st.text(" ")
        st.text(" ")
        st.text(" ")
        
        st.image("./images/horizontal_line.png", use_column_width=True)
        self.render_about_the_model()
               
        st.text(" ")
        st.text(" ")
        st.text(" ")

        st.image("./images/horizontal_line.png", use_column_width=True)
        self.render_model_performance()

        st.text(" ")
        st.text(" ")
        st.text(" ")
        
        st.image("./images/horizontal_line.png", use_column_width=True)
        self.render_model_insights()
        
        st.text(" ")
        st.text(" ")
        st.text(" ")

        st.image("./images/horizontal_line.png", use_column_width=True)
        self.render_model_predictions()

app = Application()
app.render_app()